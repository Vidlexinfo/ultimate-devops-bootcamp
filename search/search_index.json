{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Ultimate Devops Bootcamp by School of Devops This is a Lab Guide which goes along with the Ultimate Devops Bootcamp Course by School of Devops. For information about the devops trainign courses visit schoolofdevops.com . Team Gourav Shah","title":"Home"},{"location":"#welcome-to-ultimate-devops-bootcamp-by-school-of-devops","text":"This is a Lab Guide which goes along with the Ultimate Devops Bootcamp Course by School of Devops. For information about the devops trainign courses visit schoolofdevops.com .","title":"Welcome to Ultimate Devops  Bootcamp by School of Devops"},{"location":"#team","text":"Gourav Shah","title":"Team"},{"location":"010_docker_envi/","text":"Setting up and validating docker environment In this chapter, we are going to set docker environment. Visit docs.docker.com this page provides all the information of how to install docker on ubuntu, mac or windows. In this page left side you can see couple of options . when you select docker CE (Docker Community Edition). Thre is also provides instructions on different os platform. There are two options docker EE docker CE Here , we going for docker for ubuntu you can use the following script. #!/bin/bash apt-get update apt-get install -y git wget # Install Docker apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - apt-key fingerprint 0EBFCD88 add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" apt-get update apt-get install -yq docker-ce After install docker using above script you can validate using following command docker version [output] Client: Version: 18.03.1-ce API version: 1.37 Go version: go1.9.5 Git commit: 9ee9f40 Built: Thu Apr 26 07:17:20 2018 OS/Arch: linux/amd64 Experimental: false Orchestrator: swarm Server: Engine: Version: 18.03.1-ce API version: 1.37 (minimum version 1.12) Go version: go1.9.5 Git commit: 9ee9f40 Built: Thu Apr 26 07:15:30 2018 OS/Arch: linux/amd64 Experimental: false Run docker Hello-world sudo docker run hello-world [output] Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world d1725b59e92d: Pull complete Digest: sha256:0add3ace90ecb4adbf7777e9aacf18357296e799f81cabc9fde470971e499788 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ Play-with-docker If you don't have way to install docker locally even remote server. you can also use protal play-with-docker Here, we have to login with your docker hub id and password. if you don't have docker hub id and password you should need to create your docker hub id and password docker hub . Play-with-docker gives you working docker environment. you can see the UI Here, In this Page left side create instance label click on on that label they provide you docker envirenment. you can also ren the following command. docker version command shows you to all the information of docker like version, api version Git commit etc. docker version [output] Client: Version: 18.03.1-ce API version: 1.37 Go version: go1.9.5 Git commit: 9ee9f40 Built: Thu Apr 26 07:17:20 2018 OS/Arch: linux/amd64 Experimental: false Orchestrator: swarm Server: Engine: Version: 18.03.1-ce API version: 1.37 (minimum version 1.12) Go version: go1.9.5 Git commit: 9ee9f40 Built: Thu Apr 26 07:15:30 2018 OS/Arch: linux/amd64 Experimental: false Docker hello world image docker run hello-world [output] Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world d1725b59e92d: Pull complete Digest: sha256:0add3ace90ecb4adbf7777e9aacf18357296e799f81cabc9fde470971e499788 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ you also need access to of docker hub. docker hub is registry where you can find bunch of images. Images are self sufficient application package into along with dependency including the os file system as well. each image has different tag, tag represents the diffrent version of perticular image tipically which map the application as well. you can use base ubuntu image docker run -it ubuntu bash [output] Unable to find image 'ubuntu:latest' locally latest: Pulling from library/ubuntu 124c757242f8: Pull complete 9d866f8bde2a: Pull complete fa3f2f277e67: Pull complete 398d32b153e8: Pull complete afde35469481: Pull complete Digest: sha256:de774a3145f7ca4f0bd144c7d4ffb2931e06634f11529653b23eba85aef8e378 Status: Downloaded newer image for ubuntu:latest and you will be inside the ubuntu image container. or you can also run docker system info this is show you how many container are running , paused, stoped . this also show you how many imanges are avaible . this show all the information of docker daemon. sudo docker system info [output] Containers: 2 Running: 0 Paused: 0 Stopped: 2 Images: 15 Server Version: 18.03.1-ce Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 773c489c9c1b21a6d78b5c538cd395416ec50f88 runc version: 4fc53a81fb7c994640722ac585fa9ca548971871 init version: 949e6fa Security Options: apparmor seccomp Profile: default Kernel Version: 4.13.0-45-generic Operating System: Ubuntu 16.04.4 LTS OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 3.743GiB Name: gops-Inspiron-3521 ID: EUYA:2G3W:NDNJ:4TRA:VQUX:DWPX:S274:4V26:HOHP:NC4M:YOLJ:ITMH Docker Root Dir: /var/lib/docker Debug Mode (client): false Debug Mode (server): false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries: 127.0.0.0/8 Live Restore Enabled: false docker -v only shows you docker version and build [output] Docker version 18.03.1-ce, build 9ee9f40 We can use docker cli to interact with docker daemon. Various functions of docker command is given below. Try this yourself by runnig $sudo docker command docker [output] Usage: docker COMMAND A self-sufficient runtime for containers Options: --config string Location of client config files (default \"/home/gops/.docker\") -D, --debug Enable debug mode -H, --host list Daemon socket(s) to connect to -l, --log-level string Set the logging level (\"debug\"|\"info\"|\"warn\"|\"error\"|\"fatal\") (default \"info\") --tls Use TLS; implied by --tlsverify --tlscacert string Trust certs signed only by this CA (default \"/home/gops/.docker/ca.pem\") --tlscert string Path to TLS certificate file (default \"/home/gops/.docker/cert.pem\") --tlskey string Path to TLS key file (default \"/home/gops/.docker/key.pem\") --tlsverify Use TLS and verify the remote -v, --version Print version information and quit Management Commands: checkpoint Manage checkpoints config Manage Docker configs container Manage containers image Manage images network Manage networks node Manage Swarm nodes plugin Manage plugins secret Manage Docker secrets service Manage services swarm Manage Swarm system Manage Docker trust Manage trust on Docker images volume Manage volumes Commands: attach Attach local standard input, output, and error streams to a running container build Build an image from a Dockerfile commit Create a new image from a container's changes cp Copy files/folders between a container and the local filesystem create Create a new container deploy Deploy a new stack or update an existing stack diff Inspect changes to files or directories on a container's filesystem events Get real time events from the server exec Run a command in a running container export Export a container's filesystem as a tar archive history Show the history of an image images List images import Import the contents from a tarball to create a filesystem image info Display system-wide information inspect Return low-level information on Docker objects kill Kill one or more running containers load Load an image from a tar archive or STDIN login Log in to a Docker registry logout Log out from a Docker registry logs Fetch the logs of a container pause Pause all processes within one or more containers port List port mappings or a specific mapping for the container ps List containers pull Pull an image or a repository from a registry push Push an image or a repository to a registry rename Rename a container restart Restart one or more containers rm Remove one or more containers rmi Remove one or more images run Run a command in a new container save Save one or more images to a tar archive (streamed to STDOUT by default) search Search the Docker Hub for images start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop one or more running containers tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers version Show the Docker version information wait Block until one or more containers stop, then print their exit codes Run 'docker COMMAND --help' for more information on a command.","title":"010 docker envi"},{"location":"010_docker_envi/#setting-up-and-validating-docker-environment","text":"In this chapter, we are going to set docker environment. Visit docs.docker.com this page provides all the information of how to install docker on ubuntu, mac or windows. In this page left side you can see couple of options . when you select docker CE (Docker Community Edition). Thre is also provides instructions on different os platform. There are two options docker EE docker CE Here , we going for docker for ubuntu you can use the following script. #!/bin/bash apt-get update apt-get install -y git wget # Install Docker apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - apt-key fingerprint 0EBFCD88 add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" apt-get update apt-get install -yq docker-ce After install docker using above script you can validate using following command docker version [output] Client: Version: 18.03.1-ce API version: 1.37 Go version: go1.9.5 Git commit: 9ee9f40 Built: Thu Apr 26 07:17:20 2018 OS/Arch: linux/amd64 Experimental: false Orchestrator: swarm Server: Engine: Version: 18.03.1-ce API version: 1.37 (minimum version 1.12) Go version: go1.9.5 Git commit: 9ee9f40 Built: Thu Apr 26 07:15:30 2018 OS/Arch: linux/amd64 Experimental: false Run docker Hello-world sudo docker run hello-world [output] Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world d1725b59e92d: Pull complete Digest: sha256:0add3ace90ecb4adbf7777e9aacf18357296e799f81cabc9fde470971e499788 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/","title":"Setting up and validating docker environment"},{"location":"010_docker_envi/#play-with-docker","text":"If you don't have way to install docker locally even remote server. you can also use protal play-with-docker Here, we have to login with your docker hub id and password. if you don't have docker hub id and password you should need to create your docker hub id and password docker hub . Play-with-docker gives you working docker environment. you can see the UI Here, In this Page left side create instance label click on on that label they provide you docker envirenment. you can also ren the following command. docker version command shows you to all the information of docker like version, api version Git commit etc. docker version [output] Client: Version: 18.03.1-ce API version: 1.37 Go version: go1.9.5 Git commit: 9ee9f40 Built: Thu Apr 26 07:17:20 2018 OS/Arch: linux/amd64 Experimental: false Orchestrator: swarm Server: Engine: Version: 18.03.1-ce API version: 1.37 (minimum version 1.12) Go version: go1.9.5 Git commit: 9ee9f40 Built: Thu Apr 26 07:15:30 2018 OS/Arch: linux/amd64 Experimental: false Docker hello world image docker run hello-world [output] Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world d1725b59e92d: Pull complete Digest: sha256:0add3ace90ecb4adbf7777e9aacf18357296e799f81cabc9fde470971e499788 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ you also need access to of docker hub. docker hub is registry where you can find bunch of images. Images are self sufficient application package into along with dependency including the os file system as well. each image has different tag, tag represents the diffrent version of perticular image tipically which map the application as well. you can use base ubuntu image docker run -it ubuntu bash [output] Unable to find image 'ubuntu:latest' locally latest: Pulling from library/ubuntu 124c757242f8: Pull complete 9d866f8bde2a: Pull complete fa3f2f277e67: Pull complete 398d32b153e8: Pull complete afde35469481: Pull complete Digest: sha256:de774a3145f7ca4f0bd144c7d4ffb2931e06634f11529653b23eba85aef8e378 Status: Downloaded newer image for ubuntu:latest and you will be inside the ubuntu image container. or you can also run docker system info this is show you how many container are running , paused, stoped . this also show you how many imanges are avaible . this show all the information of docker daemon. sudo docker system info [output] Containers: 2 Running: 0 Paused: 0 Stopped: 2 Images: 15 Server Version: 18.03.1-ce Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 773c489c9c1b21a6d78b5c538cd395416ec50f88 runc version: 4fc53a81fb7c994640722ac585fa9ca548971871 init version: 949e6fa Security Options: apparmor seccomp Profile: default Kernel Version: 4.13.0-45-generic Operating System: Ubuntu 16.04.4 LTS OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 3.743GiB Name: gops-Inspiron-3521 ID: EUYA:2G3W:NDNJ:4TRA:VQUX:DWPX:S274:4V26:HOHP:NC4M:YOLJ:ITMH Docker Root Dir: /var/lib/docker Debug Mode (client): false Debug Mode (server): false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries: 127.0.0.0/8 Live Restore Enabled: false docker -v only shows you docker version and build [output] Docker version 18.03.1-ce, build 9ee9f40 We can use docker cli to interact with docker daemon. Various functions of docker command is given below. Try this yourself by runnig $sudo docker command docker [output] Usage: docker COMMAND A self-sufficient runtime for containers Options: --config string Location of client config files (default \"/home/gops/.docker\") -D, --debug Enable debug mode -H, --host list Daemon socket(s) to connect to -l, --log-level string Set the logging level (\"debug\"|\"info\"|\"warn\"|\"error\"|\"fatal\") (default \"info\") --tls Use TLS; implied by --tlsverify --tlscacert string Trust certs signed only by this CA (default \"/home/gops/.docker/ca.pem\") --tlscert string Path to TLS certificate file (default \"/home/gops/.docker/cert.pem\") --tlskey string Path to TLS key file (default \"/home/gops/.docker/key.pem\") --tlsverify Use TLS and verify the remote -v, --version Print version information and quit Management Commands: checkpoint Manage checkpoints config Manage Docker configs container Manage containers image Manage images network Manage networks node Manage Swarm nodes plugin Manage plugins secret Manage Docker secrets service Manage services swarm Manage Swarm system Manage Docker trust Manage trust on Docker images volume Manage volumes Commands: attach Attach local standard input, output, and error streams to a running container build Build an image from a Dockerfile commit Create a new image from a container's changes cp Copy files/folders between a container and the local filesystem create Create a new container deploy Deploy a new stack or update an existing stack diff Inspect changes to files or directories on a container's filesystem events Get real time events from the server exec Run a command in a running container export Export a container's filesystem as a tar archive history Show the history of an image images List images import Import the contents from a tarball to create a filesystem image info Display system-wide information inspect Return low-level information on Docker objects kill Kill one or more running containers load Load an image from a tar archive or STDIN login Log in to a Docker registry logout Log out from a Docker registry logs Fetch the logs of a container pause Pause all processes within one or more containers port List port mappings or a specific mapping for the container ps List containers pull Pull an image or a repository from a registry push Push an image or a repository to a registry rename Rename a container restart Restart one or more containers rm Remove one or more containers rmi Remove one or more images run Run a command in a new container save Save one or more images to a tar archive (streamed to STDOUT by default) search Search the Docker Hub for images start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop one or more running containers tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers version Show the Docker version information wait Block until one or more containers stop, then print their exit codes Run 'docker COMMAND --help' for more information on a command.","title":"Play-with-docker"},{"location":"010_introduction/","text":"","title":"010 introduction"},{"location":"020_install_jenkins_jfrog_artifactory/","text":"Jenkins Jenkins is a essential automation tool to setup Continuous Integration. Its the integrator which helps you build your development, testing and deployment workflow and create job pipelines. It also adds visibility to all stake holders including the Dev, QA, Ops teams involved in building, testing and deploying the product. JFrog Artifactory JFrog Artifactory is the only Universal Repository Manager supporting all major packaging formats, build tools and CI servers. Shipping updates continuously and automatically has become a critical element of any successful operation. Setting up CI-CD Environment with Docker-Compose This is the easiest method to setup Jenkins and is a recommended option. Installing Docker Engine and Docker-Compose Proceed with installing Docker Engine and docker-compose on your choice of Operating System. For details on how to install docker visit the official installation page at docker engine docker-compose We assume you have installed docker, docker-compose and are ready to launch containers before proceeding. To validate docker environment run. docker ps If the above command goes through without errors, you are all set. Running Jenkins and Artifactory using Docker-Compose Once you all set, now you can create compose file for Jenkins and Artifactory. This is the simplest way of installing Jenkins, Artifactory and requires minimal efforts. docker-compose-CI-CD.yml version: '2' networks: custom: driver: bridge ipam: driver: default config: - subnet: 192.168.61.0/28 services: jenkins: image: jenkins ports: - \"8080:8080\" - \"50000:50000\" volumes: - \"/var/run/docker.sock:/var/run/docker.sock\" networks: custom: ipv4_address: 192.168.61.4 domainname: codespaces.io hostname: jenkins restart: always artifactory: image: docker.bintray.io/jfrog/artifactory-oss ports: - \"8081:8081\" networks: custom: ipv4_address: 192.168.61.5 domainname: codespaces.io hostname: artifactory restart: always Once you are ready with compose file, run below command to make it running docker-compose -f docker-compose-CI-CD.yml up -d If you install it using the instructions above, find out the IP address and go to http://YOUR_IP_ADDRESS:8080 to access jenkins UI http://YOUR_IP_ADDRESS:8081 to access artifactory UI To start/stop containers with docker, use the following commands, docker start [container-id] docker stop [container-id] Common Post Installation Steps Jenkins After the installation, you will be asked for password. The password will be saved in the following file. /var/jenkins_home/secrets/initialAdminPassword Password can be also fetched from the logs. You could run the following command to view the password, docker logs jenkins or to follow the logs docker logs -f jenkins [use ^c to come back to the terminal] Click on Select Plugins to Install when given an option. This will let you choose the plugins to install on the next page. On the selection page, * Click on None to deselect all plugins Create Admin user Now we have successfully installed Jenkins and we can proceed with configurations Artifactory Default Credentials: username : admin password : password After login in you will be welcomed with this page. Click on next, You will be asked to set up admin username and password. Skip this for now and use the default credentials. After that, you will be asked to Configure a Proxy Server . Skip this step as well. In Create Repositories page, click on Generic and maven and click on Create . Then click on finish .","title":"Jenkins"},{"location":"020_install_jenkins_jfrog_artifactory/#jenkins","text":"Jenkins is a essential automation tool to setup Continuous Integration. Its the integrator which helps you build your development, testing and deployment workflow and create job pipelines. It also adds visibility to all stake holders including the Dev, QA, Ops teams involved in building, testing and deploying the product.","title":"Jenkins"},{"location":"020_install_jenkins_jfrog_artifactory/#jfrog-artifactory","text":"JFrog Artifactory is the only Universal Repository Manager supporting all major packaging formats, build tools and CI servers. Shipping updates continuously and automatically has become a critical element of any successful operation.","title":"JFrog Artifactory"},{"location":"020_install_jenkins_jfrog_artifactory/#setting-up-ci-cd-environment-with-docker-compose","text":"This is the easiest method to setup Jenkins and is a recommended option.","title":"Setting up CI-CD Environment with Docker-Compose"},{"location":"020_install_jenkins_jfrog_artifactory/#installing-docker-engine-and-docker-compose","text":"Proceed with installing Docker Engine and docker-compose on your choice of Operating System. For details on how to install docker visit the official installation page at docker engine docker-compose We assume you have installed docker, docker-compose and are ready to launch containers before proceeding. To validate docker environment run. docker ps If the above command goes through without errors, you are all set.","title":"Installing Docker Engine and Docker-Compose"},{"location":"020_install_jenkins_jfrog_artifactory/#running-jenkins-and-artifactory-using-docker-compose","text":"Once you all set, now you can create compose file for Jenkins and Artifactory. This is the simplest way of installing Jenkins, Artifactory and requires minimal efforts. docker-compose-CI-CD.yml version: '2' networks: custom: driver: bridge ipam: driver: default config: - subnet: 192.168.61.0/28 services: jenkins: image: jenkins ports: - \"8080:8080\" - \"50000:50000\" volumes: - \"/var/run/docker.sock:/var/run/docker.sock\" networks: custom: ipv4_address: 192.168.61.4 domainname: codespaces.io hostname: jenkins restart: always artifactory: image: docker.bintray.io/jfrog/artifactory-oss ports: - \"8081:8081\" networks: custom: ipv4_address: 192.168.61.5 domainname: codespaces.io hostname: artifactory restart: always Once you are ready with compose file, run below command to make it running docker-compose -f docker-compose-CI-CD.yml up -d If you install it using the instructions above, find out the IP address and go to http://YOUR_IP_ADDRESS:8080 to access jenkins UI http://YOUR_IP_ADDRESS:8081 to access artifactory UI To start/stop containers with docker, use the following commands, docker start [container-id] docker stop [container-id]","title":"Running Jenkins and Artifactory using Docker-Compose"},{"location":"020_install_jenkins_jfrog_artifactory/#common-post-installation-steps","text":"","title":"Common Post Installation Steps"},{"location":"020_install_jenkins_jfrog_artifactory/#jenkins_1","text":"After the installation, you will be asked for password. The password will be saved in the following file. /var/jenkins_home/secrets/initialAdminPassword Password can be also fetched from the logs. You could run the following command to view the password, docker logs jenkins or to follow the logs docker logs -f jenkins [use ^c to come back to the terminal] Click on Select Plugins to Install when given an option. This will let you choose the plugins to install on the next page. On the selection page, * Click on None to deselect all plugins Create Admin user Now we have successfully installed Jenkins and we can proceed with configurations","title":"Jenkins"},{"location":"020_install_jenkins_jfrog_artifactory/#artifactory","text":"Default Credentials: username : admin password : password After login in you will be welcomed with this page. Click on next, You will be asked to set up admin username and password. Skip this for now and use the default credentials. After that, you will be asked to Configure a Proxy Server . Skip this step as well. In Create Repositories page, click on Generic and maven and click on Create . Then click on finish .","title":"Artifactory"},{"location":"021_other_ways_to_setup_environment/","text":"Setting up environment using Vagrant (Pre bundled Image) This is the simplest way of setting up the learning environment for this course following are the pre requisites, You should have setup the environment by following the steps mentioned on the Common Lab Setup Instructions You should also have received a pre pre bundled vagrant box (e.g. devops-ci-v01.box) with jenkins and docker installed and copied over to your development machine (windows/Mac/Linux Laptop/Desktop) You should have downloaded the lab-setup repository Import the Vagrant Box Open a bash terminal using ConEMU or Git Bash, change into the directory where you have copied over the box file and import it using, vagrant box add devops devops-ci-v01.box Validate that the box is available on your system by running, vagrant box list [output] devops (virtualbox, 0) If you see devops in the list of available boxes, the template is been successfully imported. Now lets bring up the Vagrant environment. To do so, you need to open a bash shell either using ConEmu or Git Bash and cd into lab-setup/ci/virtual directory. In this directory, you should see a Vagrantfile. All vagrant commands to manage a VM are run from a directory where this Vagrantfile is. cd lab-setup/ci/virtual vagrant up vagrant ssh After you run vagrant ssh , you should have been logged into the environment. Validate that Jenkins comes up at the following URL http://YOUR_IP_ADDRESS:8080 Setting up learning environment on Ubuntu 14.04 Jenkins requires Java Development Kit to be installed first. Installing Pre Requisites OpenJDK 7 Installing OpenJDK 7 $ sudo apt-get install add-apt-repository $ sudo add-apt-repository ppa:openjdk-r/ppa $ sudo apt-get update $ sudo apt-get install openjdk-8-jdk Run the following command to set the default Java and Javac: $ sudo update-alternatives --config java $ sudo update-alternatives --config javac If there is more than one Java versions installed on your system, type in a number to select a Java version. If you face any dependency error use this command to resolve the dependencies. $ sudo apt-get -f install Verifying Installation $ sudo java -version Installing Maven 3 Installing Maven $ sudo apt-get install maven Verifying Installation $ sudo mvn -version Installing Jenkins To install Jenkins in Ubuntu visit jenkins.io Download the specific version of .deb package using wget in tmp folder and proceed with depackaging. Note: In our case we use jenkins_1.651.3 $ sudo wget http://pkg.jenkins-ci.org/debian-stable/binary/jenkins_2.19.4_all.deb $ sudo dpkg -i jenkins_1.651.3_all.deb Verifying Installation by checking the status of Jenkins service. $ sudo ps -aux | grep jenkins Jenkins service is running in port 8080 Visit Jenkins Console in browser by visitig http://localhost:8080 replace localhost with the VMs' IP. Setting up learning environment on CentOS/RHEL 6.x Jenkins requires Java Development Kit to be installed first. Installing Pre Requisites Installing OpenJDK 7 yum install -y <jdk> Installing Jenkins sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat-stable/jenkins.repo sudo rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key sudo yum install jenkins sudo service jenkins start Installing Docker Since this tutorial uses docker to deploy application, its essential to install Docker and Docker Compose . Refer to the following resources to install Docker Docker Installation Guide Docker Compose Installation Guide","title":"021 other ways to setup environment"},{"location":"021_other_ways_to_setup_environment/#setting-up-environment-using-vagrant-pre-bundled-image","text":"This is the simplest way of setting up the learning environment for this course following are the pre requisites, You should have setup the environment by following the steps mentioned on the Common Lab Setup Instructions You should also have received a pre pre bundled vagrant box (e.g. devops-ci-v01.box) with jenkins and docker installed and copied over to your development machine (windows/Mac/Linux Laptop/Desktop) You should have downloaded the lab-setup repository","title":"Setting up environment using  Vagrant (Pre bundled Image)"},{"location":"021_other_ways_to_setup_environment/#import-the-vagrant-box","text":"Open a bash terminal using ConEMU or Git Bash, change into the directory where you have copied over the box file and import it using, vagrant box add devops devops-ci-v01.box Validate that the box is available on your system by running, vagrant box list [output] devops (virtualbox, 0) If you see devops in the list of available boxes, the template is been successfully imported. Now lets bring up the Vagrant environment. To do so, you need to open a bash shell either using ConEmu or Git Bash and cd into lab-setup/ci/virtual directory. In this directory, you should see a Vagrantfile. All vagrant commands to manage a VM are run from a directory where this Vagrantfile is. cd lab-setup/ci/virtual vagrant up vagrant ssh After you run vagrant ssh , you should have been logged into the environment. Validate that Jenkins comes up at the following URL http://YOUR_IP_ADDRESS:8080","title":"Import the Vagrant Box"},{"location":"021_other_ways_to_setup_environment/#setting-up-learning-environment-on-ubuntu-1404","text":"Jenkins requires Java Development Kit to be installed first.","title":"Setting up learning environment on Ubuntu 14.04"},{"location":"021_other_ways_to_setup_environment/#installing-pre-requisites","text":"","title":"Installing Pre Requisites"},{"location":"021_other_ways_to_setup_environment/#openjdk-7","text":"Installing OpenJDK 7 $ sudo apt-get install add-apt-repository $ sudo add-apt-repository ppa:openjdk-r/ppa $ sudo apt-get update $ sudo apt-get install openjdk-8-jdk Run the following command to set the default Java and Javac: $ sudo update-alternatives --config java $ sudo update-alternatives --config javac If there is more than one Java versions installed on your system, type in a number to select a Java version. If you face any dependency error use this command to resolve the dependencies. $ sudo apt-get -f install Verifying Installation $ sudo java -version","title":"OpenJDK 7"},{"location":"021_other_ways_to_setup_environment/#installing-maven-3","text":"Installing Maven $ sudo apt-get install maven Verifying Installation $ sudo mvn -version","title":"Installing Maven 3"},{"location":"021_other_ways_to_setup_environment/#installing-jenkins","text":"To install Jenkins in Ubuntu visit jenkins.io Download the specific version of .deb package using wget in tmp folder and proceed with depackaging. Note: In our case we use jenkins_1.651.3 $ sudo wget http://pkg.jenkins-ci.org/debian-stable/binary/jenkins_2.19.4_all.deb $ sudo dpkg -i jenkins_1.651.3_all.deb Verifying Installation by checking the status of Jenkins service. $ sudo ps -aux | grep jenkins Jenkins service is running in port 8080 Visit Jenkins Console in browser by visitig http://localhost:8080 replace localhost with the VMs' IP.","title":"Installing Jenkins"},{"location":"021_other_ways_to_setup_environment/#setting-up-learning-environment-on-centosrhel-6x","text":"Jenkins requires Java Development Kit to be installed first.","title":"Setting up learning environment on CentOS/RHEL 6.x"},{"location":"021_other_ways_to_setup_environment/#installing-pre-requisites_1","text":"Installing OpenJDK 7 yum install -y <jdk>","title":"Installing Pre Requisites"},{"location":"021_other_ways_to_setup_environment/#installing-jenkins_1","text":"sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat-stable/jenkins.repo sudo rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key sudo yum install jenkins sudo service jenkins start","title":"Installing Jenkins"},{"location":"021_other_ways_to_setup_environment/#installing-docker","text":"Since this tutorial uses docker to deploy application, its essential to install Docker and Docker Compose . Refer to the following resources to install Docker Docker Installation Guide Docker Compose Installation Guide","title":"Installing Docker"},{"location":"030_install_plugins/","text":"Jenkins configurations Getting Familiar with Jenkins Console When you login to jenkins for the first time, following is the screen you would see. On the left side of the screen, on top is the menu to create new projects, to manage jenkins, to create users etc. Just below the menu is the build queue. All jobs scheduled to run get added to the queue and would appear here. Below build queue is the build executor status. This shows the status of the jobs being executed in real time. Bottom right of the page is the information about jenkins version displayed. Configuring Global Security Select Manage Jenkins -> Configure Global Security Verify checkbox for \"Enable Security\" is checked From Security Realm, \"Jenkins own database\" is selected Authorization is set to \"Logged in users can do anything\" Observe the configs and verify as per the screenshot attached below Jenkins Plugins The real magic of Jenkins lies in its rich plugins eco system. This is how tools integrate with jenkins to build a CI workflow. You want to trigger jenkins jobs after every change going into git, you have a plugin for it. You want to send a notification to your developers on a successful or failed builds, you have a notification plugin. You want to use a tool to fetch or push the build artifacts, you have a plugin for it. This is how most of the tools talk to jenkins. In this tutorial, we are going to learn a simple process to install plugins. As part of this, we will end us installing a plugin which would help us integrate jenkins with our git repository. Exploring Plugins Configurations From \"Manage Jenkins\", select \"Manage Plugins\" option. On the Manage Plugins pane you would see the following tabs, Updates Available Installed Advanced Select \"Installed\" to view the list of the plugins which came pre installed with jenkins. Installing Plugins From \"Manage Plugins\", select Available tab. On the top-right corner you should see a filter box, start typing the search term in that box. we will need below plugins to be installed for our CI-CD setup. Git Plugin Workspace Cleanup Plugin Maven Plugin NodeJS Plugin Go Plugin Git Tag Plugin Ssh Plugin Artifactory Plugin","title":"Jenkins configurations"},{"location":"030_install_plugins/#jenkins-configurations","text":"","title":"Jenkins configurations"},{"location":"030_install_plugins/#getting-familiar-with-jenkins-console","text":"When you login to jenkins for the first time, following is the screen you would see. On the left side of the screen, on top is the menu to create new projects, to manage jenkins, to create users etc. Just below the menu is the build queue. All jobs scheduled to run get added to the queue and would appear here. Below build queue is the build executor status. This shows the status of the jobs being executed in real time. Bottom right of the page is the information about jenkins version displayed.","title":"Getting Familiar with Jenkins Console"},{"location":"030_install_plugins/#configuring-global-security","text":"Select Manage Jenkins -> Configure Global Security Verify checkbox for \"Enable Security\" is checked From Security Realm, \"Jenkins own database\" is selected Authorization is set to \"Logged in users can do anything\" Observe the configs and verify as per the screenshot attached below","title":"Configuring Global Security"},{"location":"030_install_plugins/#jenkins-plugins","text":"The real magic of Jenkins lies in its rich plugins eco system. This is how tools integrate with jenkins to build a CI workflow. You want to trigger jenkins jobs after every change going into git, you have a plugin for it. You want to send a notification to your developers on a successful or failed builds, you have a notification plugin. You want to use a tool to fetch or push the build artifacts, you have a plugin for it. This is how most of the tools talk to jenkins. In this tutorial, we are going to learn a simple process to install plugins. As part of this, we will end us installing a plugin which would help us integrate jenkins with our git repository.","title":"Jenkins Plugins"},{"location":"030_install_plugins/#exploring-plugins-configurations","text":"From \"Manage Jenkins\", select \"Manage Plugins\" option. On the Manage Plugins pane you would see the following tabs, Updates Available Installed Advanced Select \"Installed\" to view the list of the plugins which came pre installed with jenkins.","title":"Exploring Plugins Configurations"},{"location":"030_install_plugins/#installing-plugins","text":"From \"Manage Plugins\", select Available tab. On the top-right corner you should see a filter box, start typing the search term in that box. we will need below plugins to be installed for our CI-CD setup. Git Plugin Workspace Cleanup Plugin Maven Plugin NodeJS Plugin Go Plugin Git Tag Plugin Ssh Plugin Artifactory Plugin","title":"Installing Plugins"},{"location":"040_jenkins_config/","text":"Jenkins Tools configurations Once you installed all plugins, we can go ahead to make required changes in configurations. Configuring Maven Go to section Maven Provide name for maven installation Select check box to install it automatically and select version to be installed. Configuring NodeJS Go to section NodeJS Provide name for nodejs installation Select check box to install it automatically and select version to be installed. You can provide names to install global modules, which very common for all services. Configuring Go Go to section Go Provide name for go installation Select check box to install it automatically and select version to be installed. Configuring SSH for remote host Go to section SSH remote hosts in Configure Systems setting. Provide host name for hosts to ssh. Select ssh port 22. We need to provide credentials for same. We can create credentials in Configure Credentials menu. Select check box to install it automatically and select version to be installed. Configuring Artifactory Provide the server id for Artifactory server. Provide URL of Artifactory server. Provide default credentials for Artifactory. once you added credentials check the connectivity, it will provide Artifactory version (e.g 5.8.4)","title":"Jenkins Tools configurations"},{"location":"040_jenkins_config/#jenkins-tools-configurations","text":"Once you installed all plugins, we can go ahead to make required changes in configurations.","title":"Jenkins Tools configurations"},{"location":"040_jenkins_config/#configuring-maven","text":"Go to section Maven Provide name for maven installation Select check box to install it automatically and select version to be installed.","title":"Configuring Maven"},{"location":"040_jenkins_config/#configuring-nodejs","text":"Go to section NodeJS Provide name for nodejs installation Select check box to install it automatically and select version to be installed. You can provide names to install global modules, which very common for all services.","title":"Configuring NodeJS"},{"location":"040_jenkins_config/#configuring-go","text":"Go to section Go Provide name for go installation Select check box to install it automatically and select version to be installed.","title":"Configuring Go"},{"location":"040_jenkins_config/#configuring-ssh-for-remote-host","text":"Go to section SSH remote hosts in Configure Systems setting. Provide host name for hosts to ssh. Select ssh port 22. We need to provide credentials for same. We can create credentials in Configure Credentials menu. Select check box to install it automatically and select version to be installed.","title":"Configuring SSH for remote host"},{"location":"040_jenkins_config/#configuring-artifactory","text":"Provide the server id for Artifactory server. Provide URL of Artifactory server. Provide default credentials for Artifactory. once you added credentials check the connectivity, it will provide Artifactory version (e.g 5.8.4)","title":"Configuring Artifactory"},{"location":"050_jenkins_jobs/","text":"Creating First Project In this session we are going to create and launch our first project with jenkins. We will be using a free style project for this example. Types of Jobs With Jenkins you could create following kind of projects or jobs. Free Style Maven External Job Multi Configuration Jenkins Jobs Anatomy A typical style jenkins jobs has the following sections. Name/description Advanced Option Source Code Management Build Triggers Pre Build Build Post Build Creating a Simple Job Lets now create a simple job using jenkins to run a hello world program. From Jenkins Main page, click on New Item . Provide a name to the project in Item Name i.e. \"job1\". Check against Free Style Project. Next screen opens the job configuration page. On the job configuration page, Add job description. e.g., \"Our first Jenkins Job\". Skip Source Code Management and Build Triggers, and scroll down to Build configurations. From \"Add Build Step\" select Execute Shell and provide commands to execute. Since this is a mock job, you could provide following sample code, #!/bin/bash echo \"Hello World !\" sleep 10 Review and click on save to go to project page. Building Job for the First Time Click on Build Now to launch a build. Once the build is started, you would see the status in the Build History section. Once build is finished, click on the build number which starts with # . Clicking on the build number e.g. #1 will take you to the page which shows the build stats. Option of interest on this page might be Console Status which shows the run time output.","title":"Creating First Project"},{"location":"050_jenkins_jobs/#creating-first-project","text":"In this session we are going to create and launch our first project with jenkins. We will be using a free style project for this example.","title":"Creating First Project"},{"location":"050_jenkins_jobs/#types-of-jobs","text":"With Jenkins you could create following kind of projects or jobs. Free Style Maven External Job Multi Configuration","title":"Types of Jobs"},{"location":"050_jenkins_jobs/#jenkins-jobs-anatomy","text":"A typical style jenkins jobs has the following sections. Name/description Advanced Option Source Code Management Build Triggers Pre Build Build Post Build","title":"Jenkins Jobs Anatomy"},{"location":"050_jenkins_jobs/#creating-a-simple-job","text":"Lets now create a simple job using jenkins to run a hello world program. From Jenkins Main page, click on New Item . Provide a name to the project in Item Name i.e. \"job1\". Check against Free Style Project. Next screen opens the job configuration page. On the job configuration page, Add job description. e.g., \"Our first Jenkins Job\". Skip Source Code Management and Build Triggers, and scroll down to Build configurations. From \"Add Build Step\" select Execute Shell and provide commands to execute. Since this is a mock job, you could provide following sample code, #!/bin/bash echo \"Hello World !\" sleep 10 Review and click on save to go to project page.","title":"Creating a Simple Job"},{"location":"050_jenkins_jobs/#building-job-for-the-first-time","text":"Click on Build Now to launch a build. Once the build is started, you would see the status in the Build History section. Once build is finished, click on the build number which starts with # . Clicking on the build number e.g. #1 will take you to the page which shows the build stats. Option of interest on this page might be Console Status which shows the run time output.","title":"Building Job for the First Time"},{"location":"060_building_jobs_pipeline/","text":"Building Jobs Pipeline Creating More Jobs to add to pipeline Lets create 2 more jobs so that we could connect those together to setup a mock build pipeline. To create new jobs, you could click on create items, name the job and select the last option which says Copy from Another Job . For this tutorial, lets create jobs by name job2 and job3 which should be copies of job1. At the end of this exercise, you should see 3 jobs listed on jenkins dashboard as above. While creating Job2 and Job3 for the first time, do not use any build triggers. We will update the configurations while defining upstream/downstream. Connecting jobs Lets now create a pipeline by connecting these jobs together. We would create a pipeline with job1 => job2 => job3 Where, job2 should run, only if job1 is built successfully, and should trigger job3 once it builds itself successfully. We could either define both connections from job2, or go to job1 and job3 and define its relationship with job2. We would do the later. Lets open Job1 configurations and from Post Build Actions select Build Other Projects and select job2 . Lets also go to jobs3 and define a dependency on job2. To do so, you would have to scroll to Build Triggers section and select Build after other projects are built and provide job2. Upstreams and Downstreams Jenkins calls these connections as Upstreams and Downstreams . In the context of job1, its downstream is job2. And for job2, job1 is its upstream. Same goes with job2 and job3. This is depicted in the following image which shows the job2 configurations. Install Pipeline Plugin To get a better view of the complete pipeline and the workflow, we would install a plugin which allows us to create a special view for connected jobs. To install this plugin, From Manage Jenkins select Manage Plugins . Click on Available tab and start typing \"pipeline\" int he filter box. No need to press enter. Check the box against Build Pipeline Plugin , the second option, and click on the button at the bottom to \"Download and install after restart\". If you don't see this plugin in the Available list then check the Installed list to see if it is installed already. Crete Pipeline View Lets now create a pipeline view. From Jenkins dashboard click on the + symbol besides the current list view named ALL which displays all jobs. Provide a name to the view e.g. pipe1 , check the radio button for Build Pipeline View . Click on ok. From the view configurations, select initial job from the drop down menu and the number of displayed builds. Click on OK to finish configurations and show the view. Run pipelines The pipeline view reads the first job, and picks up all the jobs which are directly or indirectly connected showing you one single view of the complete workflow and the order in which it is going to be executed. Pipeline view also shows the history of job runs up to the number of instances you selected earlier in the configurations. Go trigger a Run from the pipeline view and see what happens. Make sure you have selected \"ENABLE AUTO REFRESH\" earlier from the top right corner of the screen.","title":"Building Jobs Pipeline"},{"location":"060_building_jobs_pipeline/#building-jobs-pipeline","text":"","title":"Building Jobs Pipeline"},{"location":"060_building_jobs_pipeline/#creating-more-jobs-to-add-to-pipeline","text":"Lets create 2 more jobs so that we could connect those together to setup a mock build pipeline. To create new jobs, you could click on create items, name the job and select the last option which says Copy from Another Job . For this tutorial, lets create jobs by name job2 and job3 which should be copies of job1. At the end of this exercise, you should see 3 jobs listed on jenkins dashboard as above. While creating Job2 and Job3 for the first time, do not use any build triggers. We will update the configurations while defining upstream/downstream.","title":"Creating More Jobs to add to pipeline"},{"location":"060_building_jobs_pipeline/#connecting-jobs","text":"Lets now create a pipeline by connecting these jobs together. We would create a pipeline with job1 => job2 => job3 Where, job2 should run, only if job1 is built successfully, and should trigger job3 once it builds itself successfully. We could either define both connections from job2, or go to job1 and job3 and define its relationship with job2. We would do the later. Lets open Job1 configurations and from Post Build Actions select Build Other Projects and select job2 . Lets also go to jobs3 and define a dependency on job2. To do so, you would have to scroll to Build Triggers section and select Build after other projects are built and provide job2.","title":"Connecting jobs"},{"location":"060_building_jobs_pipeline/#upstreams-and-downstreams","text":"Jenkins calls these connections as Upstreams and Downstreams . In the context of job1, its downstream is job2. And for job2, job1 is its upstream. Same goes with job2 and job3. This is depicted in the following image which shows the job2 configurations.","title":"Upstreams and Downstreams"},{"location":"060_building_jobs_pipeline/#install-pipeline-plugin","text":"To get a better view of the complete pipeline and the workflow, we would install a plugin which allows us to create a special view for connected jobs. To install this plugin, From Manage Jenkins select Manage Plugins . Click on Available tab and start typing \"pipeline\" int he filter box. No need to press enter. Check the box against Build Pipeline Plugin , the second option, and click on the button at the bottom to \"Download and install after restart\". If you don't see this plugin in the Available list then check the Installed list to see if it is installed already.","title":"Install Pipeline Plugin"},{"location":"060_building_jobs_pipeline/#crete-pipeline-view","text":"Lets now create a pipeline view. From Jenkins dashboard click on the + symbol besides the current list view named ALL which displays all jobs. Provide a name to the view e.g. pipe1 , check the radio button for Build Pipeline View . Click on ok. From the view configurations, select initial job from the drop down menu and the number of displayed builds. Click on OK to finish configurations and show the view.","title":"Crete Pipeline View"},{"location":"060_building_jobs_pipeline/#run-pipelines","text":"The pipeline view reads the first job, and picks up all the jobs which are directly or indirectly connected showing you one single view of the complete workflow and the order in which it is going to be executed. Pipeline view also shows the history of job runs up to the number of instances you selected earlier in the configurations. Go trigger a Run from the pipeline view and see what happens. Make sure you have selected \"ENABLE AUTO REFRESH\" earlier from the top right corner of the screen.","title":"Run pipelines"},{"location":"070_frontend/","text":"Build pipeline for Front End Front End pipeline contains two jobs. Unit Testing Packaging Job 1 (Unit Testing) The purpose is to validate that each unit of the software performs as designed. unit testing successfully completed, Then the next step is packaging. Suppose unit testing failed, he doesn't perform packaging. Source Code Management The Source Code is available at the github.com. You need to clone it by following url https://github.com/microservices-demo/front-end.git In Build Trigger we have select GitHub hook trigger for GITScm polling. Whatever is pushed to master i.e. github.com will immediately known by the Jenkins server . Build Environment To Build the environment we required NodeJS Build To Build the Environment we need to install the npm you can install it by following Command. Job 2 (Packaging) After the successful completion of validation then we go for packaging. After packaging we deploy the package to Artifactory. Source Code Management The Source Code is available at the github.com. You need to clone it by following url https://github.com/udbc/front-end.git/ Once the unit test successfully completed then packages are Triggered. Build Environment Before starting to build the environment we Delete workspace. Artifactory Configuration Once the Unit test and Package are completed the we deploy these artifacts to Artifactory. To download the Artifactory use the following url http://188.166.236.188.9081/artifactory Build To Build the Environment we need to install the npm you can install it by following Command. Artifactory Once everything is done then the packages are deploy to Artifactory.","title":"Build pipeline for Front End"},{"location":"070_frontend/#build-pipeline-for-front-end","text":"Front End pipeline contains two jobs. Unit Testing Packaging","title":"Build pipeline for Front End"},{"location":"070_frontend/#job-1-unit-testing","text":"The purpose is to validate that each unit of the software performs as designed. unit testing successfully completed, Then the next step is packaging. Suppose unit testing failed, he doesn't perform packaging.","title":"Job 1 (Unit Testing)"},{"location":"070_frontend/#source-code-management","text":"The Source Code is available at the github.com. You need to clone it by following url https://github.com/microservices-demo/front-end.git In Build Trigger we have select GitHub hook trigger for GITScm polling. Whatever is pushed to master i.e. github.com will immediately known by the Jenkins server .","title":"Source Code Management"},{"location":"070_frontend/#build-environment","text":"To Build the environment we required NodeJS","title":"Build Environment"},{"location":"070_frontend/#build","text":"To Build the Environment we need to install the npm you can install it by following Command.","title":"Build"},{"location":"070_frontend/#job-2-packaging","text":"After the successful completion of validation then we go for packaging. After packaging we deploy the package to Artifactory.","title":"Job 2 (Packaging)"},{"location":"070_frontend/#source-code-management_1","text":"The Source Code is available at the github.com. You need to clone it by following url https://github.com/udbc/front-end.git/ Once the unit test successfully completed then packages are Triggered.","title":"Source Code Management"},{"location":"070_frontend/#build-environment_1","text":"Before starting to build the environment we Delete workspace.","title":"Build Environment"},{"location":"070_frontend/#artifactory-configuration","text":"Once the Unit test and Package are completed the we deploy these artifacts to Artifactory. To download the Artifactory use the following url http://188.166.236.188.9081/artifactory","title":"Artifactory Configuration"},{"location":"070_frontend/#build_1","text":"To Build the Environment we need to install the npm you can install it by following Command.","title":"Build"},{"location":"070_frontend/#artifactory","text":"Once everything is done then the packages are deploy to Artifactory.","title":"Artifactory"},{"location":"080_catalogue/","text":"Build pipeline for Catalogue Catalogue pipeline contains two jobs. Unit Testing Packaging Job 1 (Unit Testing) Jenkins provides an out of box functionality for Junit, and provides a host of plugins for unit testing for other technologies. Unit test verify small block of code behaves as expected under a well-defined set of external conditions. Unit test aim to isolate the code under test. Once the unit testing is successful it goes to next job called packaging. General the source code of this available on the github.com use the following link to download project. git clone https://github.com/udbc/catalogue.git/ Source Code Management To get information related to source code management click on unit_test-catalogue and click on configure In source code management we select option None Build Triggers In BUILD TRIGGERS we select the option Github hook trigger for GITScm polling . This option states that whatever is triggered or pushed to master i.e. github.com will immediately know by the jenkins server . Build In Build Execute shell script on remote host using ssh command export GOPATH=/opt/go export path=\"/opt/go/bin:$PATH\" cd /tmp/ rm -r * git clone https://github.com/udbc/catalogue.git/ cd catalogue/ cp -r images/catalogue/tmp/images gvt restore Post Build Actions If unit test build successfully completed. Its trigger to the package build. suppose unit test build failed. it doesn't trigger package build. Job 2 (Package catalogue) Once the unit test build completed. It goes to package build. Build Triggers In BUILD TRIGGERS we select the option Github hook trigger for GITScm polling . This option states that whatever is triggered or pushed to master i.e. github.com will immediately know by the jenkins server . Build Once the Jenkins server gets triggered it start building the environment . It delete workspace before building the environment. Once the packaging service is completed . We need to push the details of the package to the Artifactory server with job configuration . spec:- { \"files\": [ { \"pattern\": \"app/(*).zip\", \"target\": \"generic-local/catalogue/\", \"recursive\": \"false\" } ] } In Build Execute shell script echo \"Validating...\" which go go version export GOPATH=$WORKSPACE/opt/go export PATH=\"$WORKSPACE/opt/go/bin:$PATH\" echo \"Gopath:\" $GOPATH echo \"Path:\" $PATH echo \"Install gvt...\" go get -u github.com/FiloSottile/gvt echo \"I: Setup the repo...\" mkdir -p $WORKSPACE/opt/go/src/github.com/microservices-demo cd $WORKSPACE/opt/go/src/github.com/microservices-demo git clone https://github.com/udbc/catalogue.git echo \"I: Compile the code ...\" cd catalogue/ cp -r images $WORKSPACE/images gvt restore cd cmd/cataloguesvc/ CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o $WORKSPACE/app/catalogue github.com/microservices-demo/catalogue/cmd/cataloguesvc cd $WORKSPACE/app/ zip catalogue-$GIT_TAG_NAME.zip catalogue #mv catalogue-$GIT_TAG_NAME.zip /tmp/ #tar -cvzf catalogue-$GIT_TAG_NAME.tar.gz catalogue Artifact Repository Browser Once the packaging services deploy completed . To check artifact Repository Browser","title":"Build pipeline for Catalogue"},{"location":"080_catalogue/#build-pipeline-for-catalogue","text":"Catalogue pipeline contains two jobs. Unit Testing Packaging","title":"Build pipeline for Catalogue"},{"location":"080_catalogue/#job-1-unit-testing","text":"Jenkins provides an out of box functionality for Junit, and provides a host of plugins for unit testing for other technologies. Unit test verify small block of code behaves as expected under a well-defined set of external conditions. Unit test aim to isolate the code under test. Once the unit testing is successful it goes to next job called packaging.","title":"Job 1 (Unit Testing)"},{"location":"080_catalogue/#general","text":"the source code of this available on the github.com use the following link to download project. git clone https://github.com/udbc/catalogue.git/","title":"General"},{"location":"080_catalogue/#source-code-management","text":"To get information related to source code management click on unit_test-catalogue and click on configure In source code management we select option None","title":"Source Code Management"},{"location":"080_catalogue/#build-triggers","text":"In BUILD TRIGGERS we select the option Github hook trigger for GITScm polling . This option states that whatever is triggered or pushed to master i.e. github.com will immediately know by the jenkins server .","title":"Build Triggers"},{"location":"080_catalogue/#build","text":"In Build Execute shell script on remote host using ssh command export GOPATH=/opt/go export path=\"/opt/go/bin:$PATH\" cd /tmp/ rm -r * git clone https://github.com/udbc/catalogue.git/ cd catalogue/ cp -r images/catalogue/tmp/images gvt restore","title":"Build"},{"location":"080_catalogue/#post-build-actions","text":"If unit test build successfully completed. Its trigger to the package build. suppose unit test build failed. it doesn't trigger package build.","title":"Post Build Actions"},{"location":"080_catalogue/#job-2-package-catalogue","text":"Once the unit test build completed. It goes to package build.","title":"Job 2 (Package catalogue)"},{"location":"080_catalogue/#build-triggers_1","text":"In BUILD TRIGGERS we select the option Github hook trigger for GITScm polling . This option states that whatever is triggered or pushed to master i.e. github.com will immediately know by the jenkins server .","title":"Build Triggers"},{"location":"080_catalogue/#build_1","text":"Once the Jenkins server gets triggered it start building the environment . It delete workspace before building the environment. Once the packaging service is completed . We need to push the details of the package to the Artifactory server with job configuration . spec:- { \"files\": [ { \"pattern\": \"app/(*).zip\", \"target\": \"generic-local/catalogue/\", \"recursive\": \"false\" } ] } In Build Execute shell script echo \"Validating...\" which go go version export GOPATH=$WORKSPACE/opt/go export PATH=\"$WORKSPACE/opt/go/bin:$PATH\" echo \"Gopath:\" $GOPATH echo \"Path:\" $PATH echo \"Install gvt...\" go get -u github.com/FiloSottile/gvt echo \"I: Setup the repo...\" mkdir -p $WORKSPACE/opt/go/src/github.com/microservices-demo cd $WORKSPACE/opt/go/src/github.com/microservices-demo git clone https://github.com/udbc/catalogue.git echo \"I: Compile the code ...\" cd catalogue/ cp -r images $WORKSPACE/images gvt restore cd cmd/cataloguesvc/ CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o $WORKSPACE/app/catalogue github.com/microservices-demo/catalogue/cmd/cataloguesvc cd $WORKSPACE/app/ zip catalogue-$GIT_TAG_NAME.zip catalogue #mv catalogue-$GIT_TAG_NAME.zip /tmp/ #tar -cvzf catalogue-$GIT_TAG_NAME.tar.gz catalogue","title":"Build"},{"location":"080_catalogue/#artifact-repository-browser","text":"Once the packaging services deploy completed . To check artifact Repository Browser","title":"Artifact Repository Browser"},{"location":"080_creating_java_build_job/","text":"Creating Build Job for a Java Project In this chapter, we are going to create a job to build/compile a sample java application with maven. Creating Maven Project Before we start to create our build job, we need to install maven-integration plugin. To create a build project, From New Item, select Maven Project and provide it a name e.g. \"build\". Note : If you do not see Maven Project option on the job creation page, install Maven Integration Plugin from plugins manager. From the configuration screen, scroll to Source Code Management, select GIT and provide repository URL e.g. https://github.com/schoolofdevops/demo From Build Triggers select Poll SCM . Lets configure it to poll every 5 minutes using the following schedule H/2 * * * * Scroll down to Build step and you should see Root POM selected since its a Maven Project. In the Goals and options section, provide compile as a goal. In addition to compile, following are the goals Maven project could take. validate compile - compile source code test - unit tests package - build jar/war integration-test verify install deploy Save the job and click on Build Now . Following is a snippet from the output of the build job. [INFO] Compiling 1 source file to /var/jenkins_home/workspace/build/target/classes [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 10.216 s [INFO] Finished at: 2016-04-27T17:11:30+00:00 [INFO] Final Memory: 19M/240M [INFO] ------------------------------------------------------------------------ Waiting for Jenkins to finish collecting data [JENKINS] Archiving /var/jenkins_home/workspace/build/pom.xml to com.example.app/maven-app/3.0-release/maven-app-3.0-release.pom channel stopped Finished: SUCCESS :point_left: Prev Chapter 7: Preparing to build Java Projects :point_right: Next Chapter 9: Integrating with Artifactory","title":"Creating  Build Job for a Java Project"},{"location":"080_creating_java_build_job/#creating-build-job-for-a-java-project","text":"In this chapter, we are going to create a job to build/compile a sample java application with maven.","title":"Creating  Build Job for a Java Project"},{"location":"080_creating_java_build_job/#creating-maven-project","text":"Before we start to create our build job, we need to install maven-integration plugin. To create a build project, From New Item, select Maven Project and provide it a name e.g. \"build\". Note : If you do not see Maven Project option on the job creation page, install Maven Integration Plugin from plugins manager. From the configuration screen, scroll to Source Code Management, select GIT and provide repository URL e.g. https://github.com/schoolofdevops/demo From Build Triggers select Poll SCM . Lets configure it to poll every 5 minutes using the following schedule H/2 * * * * Scroll down to Build step and you should see Root POM selected since its a Maven Project. In the Goals and options section, provide compile as a goal. In addition to compile, following are the goals Maven project could take. validate compile - compile source code test - unit tests package - build jar/war integration-test verify install deploy Save the job and click on Build Now . Following is a snippet from the output of the build job. [INFO] Compiling 1 source file to /var/jenkins_home/workspace/build/target/classes [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 10.216 s [INFO] Finished at: 2016-04-27T17:11:30+00:00 [INFO] Final Memory: 19M/240M [INFO] ------------------------------------------------------------------------ Waiting for Jenkins to finish collecting data [JENKINS] Archiving /var/jenkins_home/workspace/build/pom.xml to com.example.app/maven-app/3.0-release/maven-app-3.0-release.pom channel stopped Finished: SUCCESS :point_left: Prev Chapter 7: Preparing to build Java Projects :point_right: Next Chapter 9: Integrating with Artifactory","title":"Creating Maven Project"},{"location":"090_carts/","text":"Build Pipeline for Cart Pipeline for the Cart contains three jobs Unit Testing. Component Testing Packages Job 1 (Unit testing) Jenkins provides an out of box functionality for Junit, and provides a host of plugins for unit testing for other technologies. Unit tests verify that a small block of code behaves as expected under a well-defined set of external conditions. Unit tests aim to isolate the code under test. Once the Unit testing is successful it goes to next job called Component testing General The source Code of this project will be available on the github.com. Project url: https://github.com/udbc/carts.git/ Source Code Management To get the information related source code management click on the unit_test_carts and the click on configure In Source Code Management we select the option NONE . In BUILD TRIGGERS we select the option GitHub hook trigger for GITScm polling . This option states that whatever is triggered or pushed to the master i.e. github.com will immediately known by the jenkins server . Build Enviornment Once the Jenkins server gets triggered it starts building the environment. It deletes the workspace before building the environment. Build In this we are actually cloning are project and running the unit test module. Job 2 (Component Testing) Integration tests exercise the interactions between different components of a system. Once the component test is passed successfully it move to Packages Source Code Management To get the information related source code management click on the component_test_carts and the click on configure In Source Code Management we select the option NONE . In BUILD TRIGGERS we select the option Build after other projects are built . This option states that once the unit_test_cart is successfully done then only it can start the component testing. Build Enviornment Once the Jenkins server gets triggered it starts building the environment. Build In this we are actually cloning are project and running the component test module. Post-build Action If the unit test and component test is successfully done then only it is triggered to the package build. Job 3 (Packages) Once the Component test is passed it goes into the packages stage. The aim of packages is to depoly it to Artifactory. Source Code Management To get the information related source code management click on the package_carts and the click on configure In Source Code Management we select the option Git . It states the are repository is present on github.com Repository url:- https://github.com/udbc/carts.git In BUILD TRIGGERS we select the option GitHub hook trigger for GITScm polling . This option states that whatever is triggered or pushed to the master i.e. github.com will immediately known by the jenkins server . Build TO build it successfully we have a file called pom.xml in which the source is present. The main goal is to clean the compine package and to skip the testing part . Post-build Actions This is the section where everything build earlier i.e. unit_test_cart and component_test_carts artifacts are deployed to the Artifactory . Here we need to define the target release and target snapshot needed for the Artifactory. ARTIFACTORY :- This is where you will be able to see that the cart module have been deployed to the Artifactory .","title":"Build Pipeline for Cart"},{"location":"090_carts/#build-pipeline-for-cart","text":"Pipeline for the Cart contains three jobs Unit Testing. Component Testing Packages","title":"Build Pipeline for Cart"},{"location":"090_carts/#job-1-unit-testing","text":"Jenkins provides an out of box functionality for Junit, and provides a host of plugins for unit testing for other technologies. Unit tests verify that a small block of code behaves as expected under a well-defined set of external conditions. Unit tests aim to isolate the code under test. Once the Unit testing is successful it goes to next job called Component testing","title":"Job 1 (Unit testing)"},{"location":"090_carts/#general","text":"The source Code of this project will be available on the github.com. Project url: https://github.com/udbc/carts.git/","title":"General"},{"location":"090_carts/#source-code-management","text":"To get the information related source code management click on the unit_test_carts and the click on configure In Source Code Management we select the option NONE . In BUILD TRIGGERS we select the option GitHub hook trigger for GITScm polling . This option states that whatever is triggered or pushed to the master i.e. github.com will immediately known by the jenkins server .","title":"Source Code Management"},{"location":"090_carts/#build-enviornment","text":"Once the Jenkins server gets triggered it starts building the environment. It deletes the workspace before building the environment.","title":"Build Enviornment"},{"location":"090_carts/#build","text":"In this we are actually cloning are project and running the unit test module.","title":"Build"},{"location":"090_carts/#job-2-component-testing","text":"Integration tests exercise the interactions between different components of a system. Once the component test is passed successfully it move to Packages","title":"Job 2 (Component Testing)"},{"location":"090_carts/#source-code-management_1","text":"To get the information related source code management click on the component_test_carts and the click on configure In Source Code Management we select the option NONE . In BUILD TRIGGERS we select the option Build after other projects are built . This option states that once the unit_test_cart is successfully done then only it can start the component testing.","title":"Source Code Management"},{"location":"090_carts/#build-enviornment_1","text":"Once the Jenkins server gets triggered it starts building the environment.","title":"Build Enviornment"},{"location":"090_carts/#build_1","text":"In this we are actually cloning are project and running the component test module.","title":"Build"},{"location":"090_carts/#post-build-action","text":"If the unit test and component test is successfully done then only it is triggered to the package build.","title":"Post-build Action"},{"location":"090_carts/#job-3-packages","text":"Once the Component test is passed it goes into the packages stage. The aim of packages is to depoly it to Artifactory.","title":"Job 3 (Packages)"},{"location":"090_carts/#source-code-management_2","text":"To get the information related source code management click on the package_carts and the click on configure In Source Code Management we select the option Git . It states the are repository is present on github.com Repository url:- https://github.com/udbc/carts.git In BUILD TRIGGERS we select the option GitHub hook trigger for GITScm polling . This option states that whatever is triggered or pushed to the master i.e. github.com will immediately known by the jenkins server .","title":"Source Code Management"},{"location":"090_carts/#build_2","text":"TO build it successfully we have a file called pom.xml in which the source is present. The main goal is to clean the compine package and to skip the testing part .","title":"Build"},{"location":"090_carts/#post-build-actions","text":"This is the section where everything build earlier i.e. unit_test_cart and component_test_carts artifacts are deployed to the Artifactory . Here we need to define the target release and target snapshot needed for the Artifactory.","title":"Post-build Actions"},{"location":"090_carts/#artifactory-","text":"This is where you will be able to see that the cart module have been deployed to the Artifactory .","title":"ARTIFACTORY :-"},{"location":"Ad hoc _Modules/","text":"Ad hoc management with Modules The default configurations for ansible resides at /etc/ansible/ansible.cfg. Instead of relying on defaults, we are going to creates a custom configuration file for our project. The advantage with that is we could take this configurations on any host and execute it the same way, without touching the default system configurations. This custom configurations will essentially override the values in /etc/ansible/ansible/cfg. Validate that your new configs are picked up, ansible --version ansible-config dump Ansible ping ansible all -m ping [output] 192.168.61.12 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } 192.168.61.11 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } 192.168.61.13 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } Ad Hoc commands Try running following fire-and-forget Ad-Hoc commands... Run hostname command on all hosts Let us print the hostname of all the hosts ansible all -a hostname [output] localhost | SUCCESS | rc=0 >> ansible 192.168.61.11 | SUCCESS | rc=0 >> db 192.168.61.12 | SUCCESS | rc=0 >> app 192.168.61.13 | SUCCESS | rc=0 >> app Check the uptime How long the hosts are up ? ansible all -a uptime [Output] localhost | SUCCESS | rc=0 >> 13:17:13 up 2:21, 1 user, load average: 0.16, 0.03, 0.01 192.168.61.12 | SUCCESS | rc=0 >> 13:17:14 up 1:50, 2 users, load average: 0.00, 0.00, 0.00 192.168.61.13 | SUCCESS | rc=0 >> 13:17:14 up 1:47, 2 users, load average: 0.00, 0.00, 0.00 192.168.61.11 | SUCCESS | rc=0 >> 13:17:14 up 1:36, 2 users, load average: 0.00, 0.00, 0.00 Check memory info on app servers Does my app servers have any disk space free ? ansible app -a free [Output] 192.168.61.13 | SUCCESS | rc=0 >> total used free shared buffers cached Mem: 372916 121480 251436 776 11160 46304 -/+ buffers/cache: 64016 308900 Swap: 4128764 0 4128764 192.168.61.12 | SUCCESS | rc=0 >> total used free shared buffers cached Mem: 372916 121984 250932 776 11228 46336 -/+ buffers/cache: 64420 308496 Swap: 4128764 0 4128764 Installing packages Let us install Docker on app servers ansible app -a \"yum install -y docker-engine\" This command will fail. [Output] 192.168.61.13 | FAILED | rc=1 >> Loaded plugins: fastestmirror, prioritiesYou need to be root to perform this command. 192.168.61.12 | FAILED | rc=1 >> Loaded plugins: fastestmirror, prioritiesYou need to be root to perform this command. Run the fillowing command with sudo permissions. ansible app -s -a \"yum install -y docker-engine\" This will install docker in our app servers [Output] 192.168.61.12 | SUCCESS | rc=0 >> Loaded plugins: fastestmirror, priorities Setting up Install Process Loading mirror speeds from cached hostfile * base: mirrors.nhanhoa.com * epel: mirror.rise.ph * extras: mirror.fibergrid.in * updates: mirror.fibergrid.in 283 packages excluded due to repository priority protections Resolving Dependencies --> Running transaction check ---> Package docker-engine.x86_64 0:1.7.1-1.el6 will be installed --> Finished Dependency Resolution Dependencies Resolved ================================================================================ Package Arch Version Repository Size ================================================================================ Installing: docker-engine x86_64 1.7.1-1.el6 local_docker 4.5 M Transaction Summary ================================================================================ Install 1 Package(s) Total download size: 4.5 M Installed size: 19 M Downloading Packages: Running rpm_check_debug Running Transaction Test Transaction Test Succeeded Running Transaction Installing : docker-engine-1.7.1-1.el6.x86_64 1/1 Verifying : docker-engine-1.7.1-1.el6.x86_64 1/1 Installed: docker-engine.x86_64 0:1.7.1-1.el6 Complete! 192.168.61.13 | SUCCESS | rc=0 >> Loaded plugins: fastestmirror, priorities Setting up Install Process Loading mirror speeds from cached hostfile * base: mirror.fibergrid.in * epel: mirror.rise.ph * extras: mirror.fibergrid.in * updates: mirror.fibergrid.in 283 packages excluded due to repository priority protections Resolving Dependencies --> Running transaction check ---> Package docker-engine.x86_64 0:1.7.1-1.el6 will be installed --> Finished Dependency Resolution Dependencies Resolved ================================================================================ Package Arch Version Repository Size ================================================================================ Installing: docker-engine x86_64 1.7.1-1.el6 local_docker 4.5 M Transaction Summary ================================================================================ Install 1 Package(s) Total download size: 4.5 M Installed size: 19 M Downloading Packages: Running rpm_check_debug Running Transaction Test Transaction Test Succeeded Running Transaction Installing : docker-engine-1.7.1-1.el6.x86_64 1/1 Verifying : docker-engine-1.7.1-1.el6.x86_64 1/1 Installed: docker-engine.x86_64 0:1.7.1-1.el6 Complete! Running commands one machine at a time Do you want a command to run on one machine at a time ? ansible all -f 1 -a \"free\" Using modules to manage the state of infrastructure Creating users and groups using user and group To create a group ansible app -s -m group -a \"name=admin state=present\" The output will be, 192.168.61.13 | SUCCESS => { \"changed\": true, \"gid\": 501, \"name\": \"admin\", \"state\": \"present\", \"system\": false } 192.168.61.12 | SUCCESS => { \"changed\": true, \"gid\": 501, \"name\": \"admin\", \"state\": \"present\", \"system\": false } To create a user ansible app -s -m user -a \"name=devops group=admin createhome=yes\" This will create user devops , 192.168.61.13 | SUCCESS => { \"changed\": true, \"comment\": \"\", \"createhome\": true, \"group\": 501, \"home\": \"/home/devops\", \"name\": \"devops\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"system\": false, \"uid\": 501 } 192.168.61.12 | SUCCESS => { \"changed\": true, \"comment\": \"\", \"createhome\": true, \"group\": 501, \"home\": \"/home/devops\", \"name\": \"devops\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"system\": false, \"uid\": 501 } Copy a file using copy modules We will copy file from control node to app servers. ansible app -m copy -a \"src=/vagrant/test.txt dest=/tmp/test.txt\" File will be copied over to our app server machines... 192.168.61.13 | SUCCESS => { \"changed\": true, \"checksum\": \"3160f8f941c330444aac253a9e6420cd1a65bfe2\", \"dest\": \"/tmp/test.txt\", \"gid\": 500, \"group\": \"vagrant\", \"md5sum\": \"9052de4cff7e8a18de586f785e711b97\", \"mode\": \"0664\", \"owner\": \"vagrant\", \"size\": 11, \"src\": \"/home/vagrant/.ansible/tmp/ansible-tmp-1472991990.29-63683023616899/source\", \"state\": \"file\", \"uid\": 500 } 192.168.61.12 | SUCCESS => { \"changed\": true, \"checksum\": \"3160f8f941c330444aac253a9e6420cd1a65bfe2\", \"dest\": \"/tmp/test.txt\", \"gid\": 500, \"group\": \"vagrant\", \"md5sum\": \"9052de4cff7e8a18de586f785e711b97\", \"mode\": \"0664\", \"owner\": \"vagrant\", \"size\": 11, \"src\": \"/home/vagrant/.ansible/tmp/ansible-tmp-1472991990.26-218089785548663/source\", \"state\": \"file\", \"uid\": 500 }","title":"Ad hoc  Modules"},{"location":"Ad hoc _Modules/#ad-hoc-management-with-modules","text":"The default configurations for ansible resides at /etc/ansible/ansible.cfg. Instead of relying on defaults, we are going to creates a custom configuration file for our project. The advantage with that is we could take this configurations on any host and execute it the same way, without touching the default system configurations. This custom configurations will essentially override the values in /etc/ansible/ansible/cfg. Validate that your new configs are picked up, ansible --version ansible-config dump","title":"Ad hoc management with Modules"},{"location":"Ad hoc _Modules/#ansible-ping","text":"ansible all -m ping [output] 192.168.61.12 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } 192.168.61.11 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } 192.168.61.13 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" }","title":"Ansible ping"},{"location":"Ad hoc _Modules/#ad-hoc-commands","text":"Try running following fire-and-forget Ad-Hoc commands...","title":"Ad Hoc commands"},{"location":"Ad hoc _Modules/#run-hostname-command-on-all-hosts","text":"Let us print the hostname of all the hosts ansible all -a hostname [output] localhost | SUCCESS | rc=0 >> ansible 192.168.61.11 | SUCCESS | rc=0 >> db 192.168.61.12 | SUCCESS | rc=0 >> app 192.168.61.13 | SUCCESS | rc=0 >> app","title":"Run hostname command on all hosts"},{"location":"Ad hoc _Modules/#check-the-uptime","text":"How long the hosts are up ? ansible all -a uptime [Output] localhost | SUCCESS | rc=0 >> 13:17:13 up 2:21, 1 user, load average: 0.16, 0.03, 0.01 192.168.61.12 | SUCCESS | rc=0 >> 13:17:14 up 1:50, 2 users, load average: 0.00, 0.00, 0.00 192.168.61.13 | SUCCESS | rc=0 >> 13:17:14 up 1:47, 2 users, load average: 0.00, 0.00, 0.00 192.168.61.11 | SUCCESS | rc=0 >> 13:17:14 up 1:36, 2 users, load average: 0.00, 0.00, 0.00","title":"Check the uptime"},{"location":"Ad hoc _Modules/#check-memory-info-on-app-servers","text":"Does my app servers have any disk space free ? ansible app -a free [Output] 192.168.61.13 | SUCCESS | rc=0 >> total used free shared buffers cached Mem: 372916 121480 251436 776 11160 46304 -/+ buffers/cache: 64016 308900 Swap: 4128764 0 4128764 192.168.61.12 | SUCCESS | rc=0 >> total used free shared buffers cached Mem: 372916 121984 250932 776 11228 46336 -/+ buffers/cache: 64420 308496 Swap: 4128764 0 4128764","title":"Check memory info on app servers"},{"location":"Ad hoc _Modules/#installing-packages","text":"Let us install Docker on app servers ansible app -a \"yum install -y docker-engine\" This command will fail. [Output] 192.168.61.13 | FAILED | rc=1 >> Loaded plugins: fastestmirror, prioritiesYou need to be root to perform this command. 192.168.61.12 | FAILED | rc=1 >> Loaded plugins: fastestmirror, prioritiesYou need to be root to perform this command. Run the fillowing command with sudo permissions. ansible app -s -a \"yum install -y docker-engine\" This will install docker in our app servers [Output] 192.168.61.12 | SUCCESS | rc=0 >> Loaded plugins: fastestmirror, priorities Setting up Install Process Loading mirror speeds from cached hostfile * base: mirrors.nhanhoa.com * epel: mirror.rise.ph * extras: mirror.fibergrid.in * updates: mirror.fibergrid.in 283 packages excluded due to repository priority protections Resolving Dependencies --> Running transaction check ---> Package docker-engine.x86_64 0:1.7.1-1.el6 will be installed --> Finished Dependency Resolution Dependencies Resolved ================================================================================ Package Arch Version Repository Size ================================================================================ Installing: docker-engine x86_64 1.7.1-1.el6 local_docker 4.5 M Transaction Summary ================================================================================ Install 1 Package(s) Total download size: 4.5 M Installed size: 19 M Downloading Packages: Running rpm_check_debug Running Transaction Test Transaction Test Succeeded Running Transaction Installing : docker-engine-1.7.1-1.el6.x86_64 1/1 Verifying : docker-engine-1.7.1-1.el6.x86_64 1/1 Installed: docker-engine.x86_64 0:1.7.1-1.el6 Complete! 192.168.61.13 | SUCCESS | rc=0 >> Loaded plugins: fastestmirror, priorities Setting up Install Process Loading mirror speeds from cached hostfile * base: mirror.fibergrid.in * epel: mirror.rise.ph * extras: mirror.fibergrid.in * updates: mirror.fibergrid.in 283 packages excluded due to repository priority protections Resolving Dependencies --> Running transaction check ---> Package docker-engine.x86_64 0:1.7.1-1.el6 will be installed --> Finished Dependency Resolution Dependencies Resolved ================================================================================ Package Arch Version Repository Size ================================================================================ Installing: docker-engine x86_64 1.7.1-1.el6 local_docker 4.5 M Transaction Summary ================================================================================ Install 1 Package(s) Total download size: 4.5 M Installed size: 19 M Downloading Packages: Running rpm_check_debug Running Transaction Test Transaction Test Succeeded Running Transaction Installing : docker-engine-1.7.1-1.el6.x86_64 1/1 Verifying : docker-engine-1.7.1-1.el6.x86_64 1/1 Installed: docker-engine.x86_64 0:1.7.1-1.el6 Complete!","title":"Installing packages"},{"location":"Ad hoc _Modules/#running-commands-one-machine-at-a-time","text":"Do you want a command to run on one machine at a time ? ansible all -f 1 -a \"free\"","title":"Running commands one machine at a time"},{"location":"Ad hoc _Modules/#using-modules-to-manage-the-state-of-infrastructure","text":"","title":"Using modules to manage the state of infrastructure"},{"location":"Ad hoc _Modules/#creating-users-and-groups-using-user-and-group","text":"To create a group ansible app -s -m group -a \"name=admin state=present\" The output will be, 192.168.61.13 | SUCCESS => { \"changed\": true, \"gid\": 501, \"name\": \"admin\", \"state\": \"present\", \"system\": false } 192.168.61.12 | SUCCESS => { \"changed\": true, \"gid\": 501, \"name\": \"admin\", \"state\": \"present\", \"system\": false } To create a user ansible app -s -m user -a \"name=devops group=admin createhome=yes\" This will create user devops , 192.168.61.13 | SUCCESS => { \"changed\": true, \"comment\": \"\", \"createhome\": true, \"group\": 501, \"home\": \"/home/devops\", \"name\": \"devops\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"system\": false, \"uid\": 501 } 192.168.61.12 | SUCCESS => { \"changed\": true, \"comment\": \"\", \"createhome\": true, \"group\": 501, \"home\": \"/home/devops\", \"name\": \"devops\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"system\": false, \"uid\": 501 }","title":"Creating users and groups using user and group"},{"location":"Ad hoc _Modules/#copy-a-file-using-copy-modules","text":"We will copy file from control node to app servers. ansible app -m copy -a \"src=/vagrant/test.txt dest=/tmp/test.txt\" File will be copied over to our app server machines... 192.168.61.13 | SUCCESS => { \"changed\": true, \"checksum\": \"3160f8f941c330444aac253a9e6420cd1a65bfe2\", \"dest\": \"/tmp/test.txt\", \"gid\": 500, \"group\": \"vagrant\", \"md5sum\": \"9052de4cff7e8a18de586f785e711b97\", \"mode\": \"0664\", \"owner\": \"vagrant\", \"size\": 11, \"src\": \"/home/vagrant/.ansible/tmp/ansible-tmp-1472991990.29-63683023616899/source\", \"state\": \"file\", \"uid\": 500 } 192.168.61.12 | SUCCESS => { \"changed\": true, \"checksum\": \"3160f8f941c330444aac253a9e6420cd1a65bfe2\", \"dest\": \"/tmp/test.txt\", \"gid\": 500, \"group\": \"vagrant\", \"md5sum\": \"9052de4cff7e8a18de586f785e711b97\", \"mode\": \"0664\", \"owner\": \"vagrant\", \"size\": 11, \"src\": \"/home/vagrant/.ansible/tmp/ansible-tmp-1472991990.26-218089785548663/source\", \"state\": \"file\", \"uid\": 500 }","title":"Copy a file using copy modules"},{"location":"Applying_common/","text":"Applying common configurations to all hosts In this section we are going to running comman playbook for all host. we have alredy have inventory as part of of environment file. when we apply code is always from of playbook. --- - name: common configurations for all nodes hosts: all become: true roles: - common this playbook defines for the common role roles/common/tasks/main.yml --- # tasks file for common - import_tasks: packages-Debian.yml when: ansible_os_family == 'Debian' - import_tasks: env-Debian.yml when: ansible_os_family == 'Debian' - import_tasks: supervisor.yml when: ansible_os_family == 'Debian' apply commom palyvook ansible-playbook common.yaml","title":"Applying common"},{"location":"Applying_common/#applying-common-configurations-to-all-hosts","text":"In this section we are going to running comman playbook for all host. we have alredy have inventory as part of of environment file. when we apply code is always from of playbook. --- - name: common configurations for all nodes hosts: all become: true roles: - common this playbook defines for the common role roles/common/tasks/main.yml --- # tasks file for common - import_tasks: packages-Debian.yml when: ansible_os_family == 'Debian' - import_tasks: env-Debian.yml when: ansible_os_family == 'Debian' - import_tasks: supervisor.yml when: ansible_os_family == 'Debian' apply commom palyvook ansible-playbook common.yaml","title":"Applying common configurations to all hosts"},{"location":"a_chapter/","text":"The first chapter \\label{cha:a_chapter} This is the first paragraph of the Softcover Markdown template produced with the \\softcover\\ command-line interface. It shows how to write a document in Markdown, a lightweight markup language, augmented with the kramdown converter and some custom extensions, including support for embedded \\PolyTeX, a subset of the powerful \\LaTeX\\ typesetting system.[^pronunciation] For more information, see The Softcover Book . To learn how to easily publish (and optionally sell) documents produced with Softcover, visit Softcover.io . This is the second paragraph, showing how to emphasize text.[^sample-footnote] You can also make text bold or emphasize a second way . Via embedded \\PolyTeX, Softcover also supports colored text, such as \\coloredtext{red}{red}, \\coloredtext{CornflowerBlue}{cornflower blue}, and \\coloredtexthtml{E8AB3A}{arbitrary HTML colors}. A section \\label{sec:a_section} This is a section. You can refer to it using the \\LaTeX\\ cross-reference syntax, like so: Section~\\ref{sec:a_section}. Source code This is a subsection. You can typeset code samples and other verbatim text using four spaces of indentation: def hello puts \"hello, world\" end Softcover also comes with full support for syntax-highlighted source code using kramdown's default syntax, which combines the language name with indentation: {lang=\"ruby\"} def hello puts \"hello, world\" end Softcover's Markdown mode also extends kramdown to support \"code fencing\" from GitHub-flavored Markdown: def hello puts \"hello, world!\" end The last of these can be combined with \\PolyTeX's codelisting environment to make code listings with linked cross-references (Listing~\\ref{code:hello}). \\begin{codelisting} \\codecaption{Hello, world.} \\label{code:hello} def hello puts \"hello, world!\" end \\end{codelisting} Mathematics Softcover's Markdown mode supports mathematical typesetting using \\LaTeX\\ syntax, including inline math, such as ( \\phi^2 - \\phi - 1 = 0, ) and centered math, such as [ \\phi = \\frac{1+\\sqrt{5}}{2}. ] It also supports centered equations with linked cross-reference via embedded \\PolyTeX\\ (Eq.~\\eqref{eq:phi}). \\begin{equation} \\label{eq:phi} \\phi = \\frac{1+\\sqrt{5}}{2} \\end{equation} Softcover also supports an alternate math syntax, such as {$$}\\phi^2 - \\phi - 1 = 0{/$$}, and centered math, such as {$$} \\phi = \\frac{1+\\sqrt{5}}{2}. {/$$} The \\LaTeX\\ syntax is strongly preferred, but the alternate syntax is included for maximum compatibility with other systems. Images and tables This is the second section. Softcover supports the inclusion of images, like this: Using \\LaTeX\\ labels, you can also include a caption (as in Figure~\\ref{fig:captioned_image}) or just a figure number (as in Figure~\\ref{fig:figure_number}). Tables Softcover supports raw tables via a simple table syntax: | HTTP request | URL | Action | Purpose | | GET | /users | index | page to list all users | | GET | /users/1 | show | page to show user with id 1 | | GET | /users/new | new | page to make a new user | | POST | /users | create | create a new user | | GET | /users/1/edit | edit | page to edit user with id 1 | | PATCH | /users/1 | update | update user with id 1 | | DELETE | /users/1 | destroy | delete user with id 1 | See The Softcover Book to learn how to make more complicated tables. Command-line interface Softcover comes with a command-line interface called softcover . To get more information, just run softcover help : $ softcover help Commands: softcover build, build:all # Build all formats softcover build:epub # Build EPUB softcover build:html # Build HTML softcover build:mobi # Build MOBI softcover build:pdf # Build PDF softcover build:preview # Build book preview in all formats . . . \\noindent You can run softcover help <command> to get additional help on a given command: $ softcover help build Usage: softcover build, build:all Options: -q, [--quiet] # Quiet output -s, [--silent] # Silent output Build all formats Miscellanea This is the end of the template---apart from two mostly empty chapters. In fact, let\u2019s include the last chapter in its entirety, just to see how mostly empty it is: <<(chapters/yet_another_chapter.md, lang: text) Visit The Softcover Book to learn more about what Softcover can do. [^sample-footnote]: This is a footnote. It is numbered automatically. [^pronunciation]: Pronunciations of \"LaTeX\" differ, but lay -tech is the one I prefer.","title":"The first chapter"},{"location":"a_chapter/#the-first-chapter","text":"\\label{cha:a_chapter} This is the first paragraph of the Softcover Markdown template produced with the \\softcover\\ command-line interface. It shows how to write a document in Markdown, a lightweight markup language, augmented with the kramdown converter and some custom extensions, including support for embedded \\PolyTeX, a subset of the powerful \\LaTeX\\ typesetting system.[^pronunciation] For more information, see The Softcover Book . To learn how to easily publish (and optionally sell) documents produced with Softcover, visit Softcover.io . This is the second paragraph, showing how to emphasize text.[^sample-footnote] You can also make text bold or emphasize a second way . Via embedded \\PolyTeX, Softcover also supports colored text, such as \\coloredtext{red}{red}, \\coloredtext{CornflowerBlue}{cornflower blue}, and \\coloredtexthtml{E8AB3A}{arbitrary HTML colors}.","title":"The first chapter"},{"location":"a_chapter/#a-section","text":"\\label{sec:a_section} This is a section. You can refer to it using the \\LaTeX\\ cross-reference syntax, like so: Section~\\ref{sec:a_section}.","title":"A section"},{"location":"a_chapter/#source-code","text":"This is a subsection. You can typeset code samples and other verbatim text using four spaces of indentation: def hello puts \"hello, world\" end Softcover also comes with full support for syntax-highlighted source code using kramdown's default syntax, which combines the language name with indentation: {lang=\"ruby\"} def hello puts \"hello, world\" end Softcover's Markdown mode also extends kramdown to support \"code fencing\" from GitHub-flavored Markdown: def hello puts \"hello, world!\" end The last of these can be combined with \\PolyTeX's codelisting environment to make code listings with linked cross-references (Listing~\\ref{code:hello}). \\begin{codelisting} \\codecaption{Hello, world.} \\label{code:hello} def hello puts \"hello, world!\" end \\end{codelisting}","title":"Source code"},{"location":"a_chapter/#mathematics","text":"Softcover's Markdown mode supports mathematical typesetting using \\LaTeX\\ syntax, including inline math, such as ( \\phi^2 - \\phi - 1 = 0, ) and centered math, such as [ \\phi = \\frac{1+\\sqrt{5}}{2}. ] It also supports centered equations with linked cross-reference via embedded \\PolyTeX\\ (Eq.~\\eqref{eq:phi}). \\begin{equation} \\label{eq:phi} \\phi = \\frac{1+\\sqrt{5}}{2} \\end{equation} Softcover also supports an alternate math syntax, such as {$$}\\phi^2 - \\phi - 1 = 0{/$$}, and centered math, such as {$$} \\phi = \\frac{1+\\sqrt{5}}{2}. {/$$} The \\LaTeX\\ syntax is strongly preferred, but the alternate syntax is included for maximum compatibility with other systems.","title":"Mathematics"},{"location":"a_chapter/#images-and-tables","text":"This is the second section. Softcover supports the inclusion of images, like this: Using \\LaTeX\\ labels, you can also include a caption (as in Figure~\\ref{fig:captioned_image}) or just a figure number (as in Figure~\\ref{fig:figure_number}).","title":"Images and tables"},{"location":"a_chapter/#tables","text":"Softcover supports raw tables via a simple table syntax: | HTTP request | URL | Action | Purpose | | GET | /users | index | page to list all users | | GET | /users/1 | show | page to show user with id 1 | | GET | /users/new | new | page to make a new user | | POST | /users | create | create a new user | | GET | /users/1/edit | edit | page to edit user with id 1 | | PATCH | /users/1 | update | update user with id 1 | | DELETE | /users/1 | destroy | delete user with id 1 | See The Softcover Book to learn how to make more complicated tables.","title":"Tables"},{"location":"a_chapter/#command-line-interface","text":"Softcover comes with a command-line interface called softcover . To get more information, just run softcover help : $ softcover help Commands: softcover build, build:all # Build all formats softcover build:epub # Build EPUB softcover build:html # Build HTML softcover build:mobi # Build MOBI softcover build:pdf # Build PDF softcover build:preview # Build book preview in all formats . . . \\noindent You can run softcover help <command> to get additional help on a given command: $ softcover help build Usage: softcover build, build:all Options: -q, [--quiet] # Quiet output -s, [--silent] # Silent output Build all formats","title":"Command-line interface"},{"location":"a_chapter/#miscellanea","text":"This is the end of the template---apart from two mostly empty chapters. In fact, let\u2019s include the last chapter in its entirety, just to see how mostly empty it is: <<(chapters/yet_another_chapter.md, lang: text) Visit The Softcover Book to learn more about what Softcover can do. [^sample-footnote]: This is a footnote. It is numbered automatically. [^pronunciation]: Pronunciations of \"LaTeX\" differ, but lay -tech is the one I prefer.","title":"Miscellanea"},{"location":"another_chapter/","text":"Another chapter This is another chapter.[^numbering] It also includes a little code fencing, mainly to test an edge case for the sake of the Softcover test suite:[^why_code_fencing] $ find . \\( -name \\*.gemspec -or -name \\*.jpg \\) -type f [^numbering]: Footnotes are numbered on a per-chapter basis. [^why_code_fencing]: The test suite uses the template files to stress-test the build system. In this case, there used to be a bug when math syntax appeared in a non-math context. Including the code fencing as above ensures that any regressions will cause the test suite to fail.","title":"Another chapter"},{"location":"another_chapter/#another-chapter","text":"This is another chapter.[^numbering] It also includes a little code fencing, mainly to test an edge case for the sake of the Softcover test suite:[^why_code_fencing] $ find . \\( -name \\*.gemspec -or -name \\*.jpg \\) -type f [^numbering]: Footnotes are numbered on a per-chapter basis. [^why_code_fencing]: The test suite uses the template files to stress-test the build system. In this case, there used to be a bug when math syntax appeared in a non-math context. Including the code fencing as above ensures that any regressions will cause the test suite to fail.","title":"Another chapter"},{"location":"ansible/","text":"ansible-galaxy install -p roles geerlingguy.mysql","title":"Ansible"},{"location":"ansible_docs/","text":"Just enough Ansible to be dangerous Chapter 1: Setting up codespaces environment Chapter 2: Inventories and host patterns Chapter 3: Ad hoc management with Modules Chapter 4: Roles for modular configurations Chapter 5: Applying common configurations to all hosts License (CC-BY-NC-ND) CI-CD Setup by School of Devops is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License .","title":"Ansible"},{"location":"ansible_docs/#just-enough-ansible-to-be-dangerous","text":"Chapter 1: Setting up codespaces environment Chapter 2: Inventories and host patterns Chapter 3: Ad hoc management with Modules Chapter 4: Roles for modular configurations Chapter 5: Applying common configurations to all hosts","title":"Just enough Ansible to be dangerous"},{"location":"ansible_docs/#license-cc-by-nc-nd","text":"CI-CD Setup by School of Devops is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License .","title":"License (CC-BY-NC-ND)"},{"location":"capstone-project/","text":"Capstone Project Robotshop Robot Shop is a sample microservice application you can use as a sandbox to test and learn containerised application orchestration and monitoring techniques. It is not intended to be a comprehensive reference example of how to write a microservices application, although you will better understand some of those concepts by playing with Robot Shop. Microservices Robot Shop is composed of following microservices. Robot Shop \\ |--- Web (HTML) |--- Cart (Node) |--- Catalogue (Node) |--- Dispatch (Go) |--- User (Node) |--- Shipping (Java) |--- Payment (Python) |--- MySQL |--- Redis |--- RabbitMQ |--- MongoDB Goal: Build and Deploy all the microservices in Robot Shop using tools such as Git, Jenkins, Docker, Kubernetes, Prometheus, CSPs(AWS and GCP). Step 1: Create and commit(in future) all the code to a Git repostory hosted on Github. * Tools involved : * Git Step 2: Create one VM with following properties. * VM Properties : * Cloud: AWS * OS: Ubunt 16.04 * Size: t2.micro * Name: build-server * Open Ports: 8080 , 22 * Tools involved : * AWS console Step 3: Install Jenkins(latest) and Docker(latest) on the VM using Ansible(version 2.5) . * Tools involved : * Ansible Step 4: Create a Jenkins Pipeline which builds and tests(unit test) Shipping service. * Tools involved : * Jenkins Step 5: Create Dockerfiles for all the following services. * Services : * Web * Cart * Catalogue * Dispatch * User * Shipping Tools involved : * Docker Step 6: Create Jenkins jobs which create and pushe Docker images for the following services. * Services : * Web * Cart * Catalogue * Dispatch * User * Shipping Tools involved : Jenkins Docker Step 7: Create a Docker-compose file for the Robot Shop application with following properties. * Services : * Web port: 8080 depends_on: - catalogue - user - shipping - payment * Cart depends_on: - redis * Catalogue depends_on: - mongodb * Dispatch depends_on: - rabbitmq * User depends_on: - mongodb - redis * Shipping depends_on: - mysql * MySQL cap_add: - NET_ADMIN * RabbitMQ * Redis * MongoDB Tools involved : Docker Step 8: Create a GKE Clsuter, Create K8s manifests for the entire stack and deploy them. * Tools involved : * GCP * GKE * Kubernetes","title":"Capstone Project"},{"location":"capstone-project/#capstone-project","text":"","title":"Capstone Project"},{"location":"capstone-project/#robotshop","text":"Robot Shop is a sample microservice application you can use as a sandbox to test and learn containerised application orchestration and monitoring techniques. It is not intended to be a comprehensive reference example of how to write a microservices application, although you will better understand some of those concepts by playing with Robot Shop.","title":"Robotshop"},{"location":"capstone-project/#microservices","text":"Robot Shop is composed of following microservices. Robot Shop \\ |--- Web (HTML) |--- Cart (Node) |--- Catalogue (Node) |--- Dispatch (Go) |--- User (Node) |--- Shipping (Java) |--- Payment (Python) |--- MySQL |--- Redis |--- RabbitMQ |--- MongoDB","title":"Microservices"},{"location":"capstone-project/#goal","text":"Build and Deploy all the microservices in Robot Shop using tools such as Git, Jenkins, Docker, Kubernetes, Prometheus, CSPs(AWS and GCP).","title":"Goal:"},{"location":"capstone-project/#step-1","text":"Create and commit(in future) all the code to a Git repostory hosted on Github. * Tools involved : * Git","title":"Step 1:"},{"location":"capstone-project/#step-2","text":"Create one VM with following properties. * VM Properties : * Cloud: AWS * OS: Ubunt 16.04 * Size: t2.micro * Name: build-server * Open Ports: 8080 , 22 * Tools involved : * AWS console","title":"Step 2:"},{"location":"capstone-project/#step-3","text":"Install Jenkins(latest) and Docker(latest) on the VM using Ansible(version 2.5) . * Tools involved : * Ansible","title":"Step 3:"},{"location":"capstone-project/#step-4","text":"Create a Jenkins Pipeline which builds and tests(unit test) Shipping service. * Tools involved : * Jenkins","title":"Step 4:"},{"location":"capstone-project/#step-5","text":"Create Dockerfiles for all the following services. * Services : * Web * Cart * Catalogue * Dispatch * User * Shipping Tools involved : * Docker","title":"Step 5:"},{"location":"capstone-project/#step-6","text":"Create Jenkins jobs which create and pushe Docker images for the following services. * Services : * Web * Cart * Catalogue * Dispatch * User * Shipping Tools involved : Jenkins Docker","title":"Step 6:"},{"location":"capstone-project/#step-7","text":"Create a Docker-compose file for the Robot Shop application with following properties. * Services : * Web port: 8080 depends_on: - catalogue - user - shipping - payment * Cart depends_on: - redis * Catalogue depends_on: - mongodb * Dispatch depends_on: - rabbitmq * User depends_on: - mongodb - redis * Shipping depends_on: - mysql * MySQL cap_add: - NET_ADMIN * RabbitMQ * Redis * MongoDB Tools involved : Docker","title":"Step 7:"},{"location":"capstone-project/#step-8","text":"Create a GKE Clsuter, Create K8s manifests for the entire stack and deploy them. * Tools involved : * GCP * GKE * Kubernetes","title":"Step 8:"},{"location":"ci_cd_setup/","text":"CI-CD Setup with Jenkins and JFrog Artifactory Chapter 1: Setting up CI-CD Environment Chapter 2: Jenkins Global Security and Plugins Configurations Chapter 3: Jenkins Tools Configurations Chapter 4: Jenkins Jobs Chapter 5: Building a Pipeline Chapter 6: Build Pipeline For Front-End Chapter 7: Build Pipeline For Catalogue Chapter 8: Build Pipeline For Carts Chapter 9: Just Enough Docker for a Devops Practitioner License (CC-BY-NC-ND) CI-CD Setup by School of Devops is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License .","title":"CI-CD Setup with Jenkins and JFrog Artifactory"},{"location":"ci_cd_setup/#ci-cd-setup-with-jenkins-and-jfrog-artifactory","text":"Chapter 1: Setting up CI-CD Environment Chapter 2: Jenkins Global Security and Plugins Configurations Chapter 3: Jenkins Tools Configurations Chapter 4: Jenkins Jobs Chapter 5: Building a Pipeline Chapter 6: Build Pipeline For Front-End Chapter 7: Build Pipeline For Catalogue Chapter 8: Build Pipeline For Carts Chapter 9: Just Enough Docker for a Devops Practitioner","title":"CI-CD Setup with Jenkins and JFrog Artifactory"},{"location":"ci_cd_setup/#license-cc-by-nc-nd","text":"CI-CD Setup by School of Devops is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License .","title":"License (CC-BY-NC-ND)"},{"location":"d02-docker-operations/","text":"available# Lab: Running and Operating Containers with Docker In this lab, you will learn, how to launch and operate linux containers with docker. Running your first Docker Container when your environment ready you can start your first docker container . when you running your first docker container you need docker registry. Go to docker public registry . when you visit docker hub you can see bunch of images available here. we are going to pick basic os image alpine . alpine is distribution of linux, ubuntu etc why we are choosing this image because of footprint of image and you can look at the size of the image look like 2 0r 3 mb that is really good for smoke testing and running smaller images. Now we have a basic understanding of docker command and sub commands, let us dive straight into launching our very first container docker container run alpine:3.6 uptime Where, we are using docker client to run a application/command uptime using an image by name alpine [output] Unable to find image 'alpine:3.6' locally 3.6: Pulling from library/alpine 117f30b7ae3d: Pull complete Digest: sha256:02eb5cfe4b721495135728ab4aea87418fd4edbfbf83612130a81191f0b2aae3 Status: Downloaded newer image for alpine:3.6 07:45:40 up 3:13, load average: 0.00, 0.00, 0.00 What happened? This command will Pull the alpine image file from docker hub, a cloud registry Create a runtime environment/ container with the above image Launch a program (called uptime) inside that container Stream that output to the terminal Stop the container once the program is exited Let's see what happens when we run that command again, [Output] docker run alpine uptime 07:48:06 up 3:15, load average: 0.00, 0.00, 0.00 Checking Status of the containers We have understood how docker run commands works. But what if you want to see list of running containers and history of containers that had run and exited? This can be done by executing the following commands docker ps [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES This command doesn't give us any information. Because, docker ps command will only show list of container(s) which are running docker ps -l [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 988f4d90d604 alpine \"uptime\" About a minute ago Exited (0) About a minute ago fervent_hypatia The -l flag shows the last run container along with other details like image it used, command it executed, return code of that command, etc., docker ps -n 2 [output] NAMES 988f4d90d604 alpine \"uptime\" About a minute ago Exited (0) About a minute ago fervent_hypatia acea3023dca4 alpine \"uptime\" 3 minutes ago Exited (0) 3 minutes ago mad_darwin Docker gives us the flexibility to show the desirable number of last run containers. This can be achieved by using -n no_of_results flag docker ps -a [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 988f4d90d604 alpine \"uptime\" About a minute ago Exited (0) About a minute ago fervent_hypatia acea3023dca4 alpine \"uptime\" 4 minutes ago Exited (0) 4 minutes ago mad_darwin 60ffa94e69ec ubuntu:14.04.3 \"bash\" 27 hours ago Exited (0) 26 hours ago infallible_meninsky dd75c04e7d2b schoolofdevops/ghost:0.3.1 \"/entrypoint.sh npm s\" 4 days ago Exited (0) 3 days ago kickass_bardeen c082972f66d6 schoolofdevops/ghost:0.3.1 \"/entrypoint.sh npm s\" 4 days ago Exited (0) 3 days ago 0.0.0.0:80->2368/tcp sodcblog This command will show all the container we have run so far. Making container persist with -idt options We can interact with docker containers by giving -it flags at the run time. These flags stand for i - Interactive t - tty d - detach docker container run -it alpine:3.4 sh [ouput] Unable to find image 'alpine:3.4' locally 3.4: Pulling from library/alpine e110a4a17941: Pull complete Digest: sha256:3dcdb92d7432d56604d4545cbd324b14e647b313626d99b889d0626de158f73a Status: Downloaded newer image for alpine:3.4 / # As you see, we have landed straight into sh shell of that container. This is the result of using -it flags and mentioning that container to run the sh shell. Don't try to exit that container yet. We have to execute some other commands in it to understand the next topic if you go inside the container Namespaced Like a full fledged OS, Docker container has its own namespaces This enables Docker container to isolate itself from the host as well as other containers Run the following commands and see that alpine container has its own namespaces and not inheriting much from host OS cat /etc/issue Welcome to Alpine Linux 3.4 Kernel \\r on an \\m (\\l) / # command pa aux [output] PID USER TIME COMMAND 1 root 0:00 sh 7 root 0:00 ps aux ifconfig [output] eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:64 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:9402 (9.1 KiB) TX bytes:0 (0.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) Essential Container Operations - list, logs, exec, cp, inspect, stop, rm In this section we are looking for some of the essential container operations like list,logs, exec etc. First we list the containers docker ps -a [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 60c643264937 alpine:3.4 \"sh\" 16 minutes ago Exited (0) 2 minutes ago kind_babbage 105b0de546cb ubuntu \"bash\" About an hour ago Exited (0) About an hour ago admiring_cori 8801c9dc6617 hello-world \"/hello\" 2 hours ago Exited (0) 2 hours ago hardcore_blackwell change the container name docker rename kind_babbage loop [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 60c643264937 alpine:3.4 \"sh\" 17 minutes ago Exited (0) 2 minutes ago loop 105b0de546cb ubuntu \"bash\" About an hour ago Exited (0) About an hour ago admiring_cori 8801c9dc6617 hello-world \"/hello\" 2 hours ago Exited (0) 2 hours ago hardcore_blackwell look at the name of the first container If you want to follow the log in real-time, use -f flag docker logs 5a75df45379c [output] PID USER TIME COMMAND 1 root 0:00 ps aux , uptime docker exec this command allows you to run command inside container docker exec e9f957dca1b7 ps aux [output] PID USER TIME COMMAND 1 root 0:00 /bin/sh 6 root 0:00 ps aux you can also use docker inspect command . this command gives you detail information about container docker inspect e9f957dca1b7 [output] [ { \"Id\": \"e9f957dca1b727be04357c77edbb2e2b257b22c0832d9f13b4ff06e3854a1237\", \"Created\": \"2018-09-25T08:49:47.619188383Z\", \"Path\": \"/bin/sh\", \"Args\": [], \"State\": { \"Status\": \"running\", \"Running\": true, \"Paused\": false, \"Restarting\": false, \"OOMKilled\": false, \"Dead\": false, \"Pid\": 19679, \"ExitCode\": 0, \"Error\": \"\", \"StartedAt\": \"2018-09-25T08:49:48.794801063Z\", \"FinishedAt\": \"0001-01-01T00:00:00Z\" }, \"Image\": \"sha256:174b26fe09c724368aa2c3cc8f2b979b915a33f7b50c94cd215380d56147cd60\", \"ResolvConfPath\": \"/var/lib/docker/containers/e9f957dca1b727be04357c77edbb2e2b257b22c0832d9f13b4ff06e3854a1237/resolv.conf\", \"HostnamePath\": \"/var/lib/docker/containers/e9f957dca1b727be04357c77edbb2e2b257b22c0832d9f13b4ff06e3854a1237/hostname\", \"HostsPath\": \"/var/lib/docker/containers/e9f957dca1b727be04357c77edbb2e2b257b22c0832d9f13b4ff06e3854a1237/hosts\", \"LogPath\": \"/var/lib/docker/containers/e9f957dca1b727be04357c77edbb2e2b257b22c0832d9f13b4ff06e3854a1237/e9f957dca1b727be04357c77edbb2e2b257b22c0832d9f13b4ff06e3854a1237-json.log\", \"Name\": \"/xenodochial_hugle\", \"RestartCount\": 0, \"Driver\": \"overlay2\", \"Platform\": \"linux\", \"MountLabel\": \"\", \"ProcessLabel\": \"\", \"AppArmorProfile\": \"docker-default\", \"ExecIDs\": null, \"HostConfig\": { \"Binds\": null, \"ContainerIDFile\": \"\", \"LogConfig\": { \"Type\": \"json-file\", \"Config\": {} }, \"NetworkMode\": \"default\", \"PortBindings\": {}, \"RestartPolicy\": { \"Name\": \"no\", \"MaximumRetryCount\": 0 }, \"AutoRemove\": false, \"VolumeDriver\": \"\", \"VolumesFrom\": null, \"CapAdd\": null, \"CapDrop\": null, \"Dns\": [], \"DnsOptions\": [], \"DnsSearch\": [], \"ExtraHosts\": null, \"GroupAdd\": null, \"IpcMode\": \"shareable\", \"Cgroup\": \"\", \"Links\": null, \"OomScoreAdj\": 0, \"PidMode\": \"\", \"Privileged\": false, \"PublishAllPorts\": false, \"ReadonlyRootfs\": false, \"SecurityOpt\": null, \"UTSMode\": \"\", \"UsernsMode\": \"\", \"ShmSize\": 67108864, \"Runtime\": \"runc\", \"ConsoleSize\": [ 0, 0 ], \"Isolation\": \"\", \"CpuShares\": 0, \"Memory\": 0, \"NanoCpus\": 0, \"CgroupParent\": \"\", \"BlkioWeight\": 0, \"BlkioWeightDevice\": [], \"BlkioDeviceReadBps\": null, \"BlkioDeviceWriteBps\": null, \"BlkioDeviceReadIOps\": null, \"BlkioDeviceWriteIOps\": null, \"CpuPeriod\": 0, \"CpuQuota\": 0, \"CpuRealtimePeriod\": 0, \"CpuRealtimeRuntime\": 0, \"CpusetCpus\": \"\", \"CpusetMems\": \"\", \"Devices\": [], \"DeviceCgroupRules\": null, \"DiskQuota\": 0, \"KernelMemory\": 0, \"MemoryReservation\": 0, \"MemorySwap\": 0, \"MemorySwappiness\": null, \"OomKillDisable\": false, \"PidsLimit\": 0, \"Ulimits\": null, \"CpuCount\": 0, \"CpuPercent\": 0, \"IOMaximumIOps\": 0, \"IOMaximumBandwidth\": 0 }, \"GraphDriver\": { \"Data\": { \"LowerDir\": \"/var/lib/docker/overlay2/517ee8ad38d79c97b5b4d9351058cf658265bbd752ffca764d6123cd5a45d7a3-init/diff:/var/lib/docker/overlay2/0ff2c00ee39d00f3cbdee2538e5bd08c0650b0a7531e6277513fb1411177c056/diff\", \"MergedDir\": \"/var/lib/docker/overlay2/517ee8ad38d79c97b5b4d9351058cf658265bbd752ffca764d6123cd5a45d7a3/merged\", \"UpperDir\": \"/var/lib/docker/overlay2/517ee8ad38d79c97b5b4d9351058cf658265bbd752ffca764d6123cd5a45d7a3/diff\", \"WorkDir\": \"/var/lib/docker/overlay2/517ee8ad38d79c97b5b4d9351058cf658265bbd752ffca764d6123cd5a45d7a3/work\" }, \"Name\": \"overlay2\" }, \"Mounts\": [], \"Config\": { \"Hostname\": \"e9f957dca1b7\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"Tty\": true, \"OpenStdin\": true, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ], \"Cmd\": [ \"/bin/sh\" ], \"ArgsEscaped\": true, \"Image\": \"alpine:3.4\", \"Volumes\": null, \"WorkingDir\": \"\", \"Entrypoint\": null, \"OnBuild\": null, \"Labels\": {} }, \"NetworkSettings\": { \"Bridge\": \"\", \"SandboxID\": \"a819dc4b5b24f71699cc58804ba227dfbfcd1431deab0bea5fe27ab5b97cc95e\", \"HairpinMode\": false, \"LinkLocalIPv6Address\": \"\", \"LinkLocalIPv6PrefixLen\": 0, \"Ports\": {}, \"SandboxKey\": \"/var/run/docker/netns/a819dc4b5b24\", \"SecondaryIPAddresses\": null, \"SecondaryIPv6Addresses\": null, \"EndpointID\": \"9de8e6914d71fc9b6d569a56ebaeae58aeb1fa21717aa1d94f200d22d82e0d37\", \"Gateway\": \"172.17.0.1\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"IPAddress\": \"172.17.0.2\", \"IPPrefixLen\": 16, \"IPv6Gateway\": \"\", \"MacAddress\": \"02:42:ac:11:00:02\", \"Networks\": { \"bridge\": { \"IPAMConfig\": null, \"Links\": null, \"Aliases\": null, \"NetworkID\": \"a379dcbffa8fff8004d04727d8898d46cf032a830a18d8507d7acbb3d14c552a\", \"EndpointID\": \"9de8e6914d71fc9b6d569a56ebaeae58aeb1fa21717aa1d94f200d22d82e0d37\", \"Gateway\": \"172.17.0.1\", \"IPAddress\": \"172.17.0.2\", \"IPPrefixLen\": 16, \"IPv6Gateway\": \"\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"MacAddress\": \"02:42:ac:11:00:02\", \"DriverOpts\": null } } } } ] docker copy docker cp testfile e9f957dca1b7:/opt docker diff docker diff e9f957dca1b7 [output] A /opt docker stop docker stop e9f 1b7 [output] e9f 1b7 docker remove docker rm e9f 1b7 [output] e9f 1b7 Publishing containers using port mapping Now, we have already start container, now access that application outside world, we are going through to launch container nginx web server image you can choose the image on docker hub registry for latest version. docker container run -idt -P nginx [output] Unable to find image 'nginx:latest' locally latest: Pulling from library/nginx 802b00ed6f79: Pull complete e9d0e0ea682b: Pull complete d8b7092b9221: Pull complete Digest: sha256:24a0c4b4a4c0eb97a1aabb8e29f18e917d05abfe1b7a7c07857230879ce7d3d3 Status: Downloaded newer image for nginx:latest 6d631d2ecfddb76481e2e75c6f14373dde5907e442231c38c062574cc4b880da Check the port docker ps [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6d631d2ecfdd nginx \"nginx -g 'daemon of\u2026\" 49 seconds ago Up 47 seconds 0.0.0.0:32768->80/tcp dreamy_gates the container are running on inside port 80 . If you want to acess on outside use the port 32768. docker are automatically pick up the port access this outside use your host_ip:32768 in browser. you can also define specific port use following command docker container run -idt -p 8888:80 nginx docker ps [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3104f3f3c062 nginx \"nginx -g 'daemon of\u2026\" 52 seconds ago Up 50 seconds 0.0.0.0:8888->80/tcp mystifying_golick 6d631d2ecfdd nginx \"nginx -g 'daemon of\u2026\" 11 minutes ago Up 11 minutes 0.0.0.0:32768->80/tcp dreamy_gates we going to deploy another web based application ghost docker run -d --name ghost -p 3001:2368 ghost:alpine [output] Unable to find image 'ghost:alpine' locally alpine: Pulling from library/ghost 4fe2ade4980c: Already exists eeb7d76f44e7: Pull complete e35f88fcc259: Pull complete b4d59ef07366: Pull complete dcee404d51ae: Pull complete f0d2c5f09664: Pull complete 6feecb37b3bd: Pull complete 4e29bf9bf09f: Pull complete Digest: sha256:d1d329a9e28096003ddbce69f3fc4a81b72c2c0c9e88426fc432fd3f0e1146e1 Status: Downloaded newer image for ghost:alpine 4c84890e1f4438a647b287751beeda02490ed7a312c05ae4a64ba7f01047a76b docker ps [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4c84890e1f44 ghost:alpine \"docker-entrypoint.s\u2026\" 40 seconds ago Up 38 seconds 0.0.0.0:3001->2368/tcp ghost 3104f3f3c062 nginx \"nginx -g 'daemon of\u2026\" 8 minutes ago Up 8 minutes 0.0.0.0:8888->80/tcp mystifying_golick 6d631d2ecfdd nginx \"nginx -g 'daemon of\u2026\" 19 minutes ago Up 19 minutes 0.0.0.0:32768->80/tcp dreamy_gates this application are running on port 3001 you can see on web browser host_ip:3001 or localhost:3001 Using docker instead of VMs to create development environments If you have using vm to runing docker container it takes some extra time to run docker container . if you want to see all the images use following command. this shows you all the present images in your local environment. docker images [output] ghost alpine fd8dde6880e2 4 days ago 422MB alpine 3.4 174b26fe09c7 13 days ago 4.82MB alpine latest 196d12cf6ab1 13 days ago 4.41MB hello-world latest 4ab4c602aa5e 2 weeks ago 1.84kB ubuntu latest cd6d8154f1e1 2 weeks ago 84.1MB if wanna see all the layers of docker image use following command docker image history ghost:alpine [output] IMAGE CREATED CREATED BY SIZE COMMENT fd8dde6880e2 4 days ago /bin/sh -c #(nop) CMD [\"node\" \"current/inde\u2026 0B <missing> 4 days ago /bin/sh -c #(nop) EXPOSE 2368/tcp 0B <missing> 4 days ago /bin/sh -c #(nop) ENTRYPOINT [\"docker-entry\u2026 0B <missing> 4 days ago /bin/sh -c #(nop) COPY file:984b6359fb5468bd\u2026 584B <missing> 4 days ago /bin/sh -c #(nop) VOLUME [/var/lib/ghost/co\u2026 0B <missing> 4 days ago /bin/sh -c #(nop) WORKDIR /var/lib/ghost 0B <missing> 4 days ago /bin/sh -c set -ex; mkdir -p \"$GHOST_INSTAL\u2026 301MB <missing> 4 days ago /bin/sh -c #(nop) ENV GHOST_VERSION=2.1.3 0B <missing> 10 days ago /bin/sh -c #(nop) ENV GHOST_CONTENT=/var/li\u2026 0B <missing> 10 days ago /bin/sh -c #(nop) ENV GHOST_INSTALL=/var/li\u2026 0B <missing> 10 days ago /bin/sh -c npm install -g \"ghost-cli@$GHOST_\u2026 51.3MB <missing> 10 days ago /bin/sh -c #(nop) ENV GHOST_CLI_VERSION=1.9\u2026 0B <missing> 13 days ago /bin/sh -c #(nop) ENV NODE_ENV=production 0B <missing> 13 days ago /bin/sh -c apk add --no-cache bash 3.82MB <missing> 13 days ago /bin/sh -c apk add --no-cache 'su-exec>=0.2' 31.8kB <missing> 13 days ago /bin/sh -c #(nop) CMD [\"node\"] 0B <missing> 13 days ago /bin/sh -c apk add --no-cache --virtual .bui\u2026 4.53MB <missing> 13 days ago /bin/sh -c #(nop) ENV YARN_VERSION=1.9.4 0B <missing> 13 days ago /bin/sh -c addgroup -g 1000 node && addu\u2026 56.7MB <missing> 13 days ago /bin/sh -c #(nop) ENV NODE_VERSION=8.12.0 0B <missing> 13 days ago /bin/sh -c #(nop) CMD [\"/bin/sh\"] 0B <missing> 13 days ago /bin/sh -c #(nop) ADD file:25c10b1d1b41d46a1\u2026 4.41MB If you want to use docker devlopment envireonment just pull the ubuntu and centos image you can pull images using docker images docker pull ubuntu [output] Using default tag: latest latest: Pulling from library/ubuntu Digest: sha256:de774a3145f7ca4f0bd144c7d4ffb2931e06634f11529653b23eba85aef8e378 Status: Image is up to date for ubuntu:latest pulling centos docker pull centos [output] Using default tag: latest latest: Pulling from library/centos 256b176beaff: Pull complete Digest: sha256:6f6d986d425aeabdc3a02cb61c02abb2e78e57357e92417d6d58332856024faf Status: Downloaded newer image for centos:latest here, the images are ready we are going to create dev environment using ubuntu image docker container run -idt --name dev --net host ubuntu bash 158dfe96692f9381842d009abfea428614fed4d9a16de68d18b408549315fbd9 docker container run -idt --name dev-centos --net host centos bash 99be0c7548ab3c762d7af2fa0cc73a5ad1505589424d82bea2c065a4f1d3bdf7 docker ps -n 2 [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 99be0c7548ab centos \"bash\" 57 seconds ago Up 56 seconds dev-centos 158dfe96692f ubuntu \"bash\" 2 minutes ago Up 2 minutes dev if you want to go inside container use following command docker exec -it dev bash you can check procees inside the container ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 18508 3004 pts/0 Ss+ 10:15 0:00 bash root 10 0.0 0.0 18508 3384 pts/1 Ss 10:20 0:00 bash root 20 0.0 0.0 34400 2772 pts/1 R+ 10:21 0:00 ps aux you can also run following command apt-get update apt-get install vim touch /opt/testfile docker stop dev docker start dev you can persist the data across. make the changes of dev environment as well , we wiiljust stop and start contaoner see the changes before start and stop. docker exec -it dev bash excute the following caommand which vim ls /opt/ Portainer - Web console to managing Docker Environemnts In this Section we are goiing for portainer web console which will allow you web based application which manages your local or remote docker environment. you can also visit the portainer docker volume create portainer_data [output] portainer_data After creating volume excute following command docker run -d -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer [output] Unable to find image 'portainer/portainer:latest' locally latest: Pulling from portainer/portainer d1e017099d17: Pull complete d4e5419541f5: Pull complete Digest: sha256:07c0e19e28e18414dd02c313c36b293758acf197d5af45077e3dd69c630e25cc Status: Downloaded newer image for portainer/portainer:latest db7a8c18cdfcae46d6ccb9d3d5ad0a48568fdc8e5827f478f0c44b95b8235bdf which will aloow container to connect to docker daemon and mange its on. docker ps [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES db7a8c18cdfc portainer/portainer \"/portainer\" About a minute ago Up About a minute 0.0.0.0:9000->9000/tcp zen_jepsen 99be0c7548ab centos \"bash\" 32 minutes ago Up 32 minutes dev-centos 158dfe96692f ubuntu \"bash\" 34 minutes ago Up 34 minutes dev 4c84890e1f44 ghost:alpine \"docker-entrypoint.s\u2026\" About an hour ago Up About an hour 0.0.0.0:3001->2368/tcp ghost 3104f3f3c062 nginx \"nginx -g 'daemon of\u2026\" About an hour ago Up About an hour 0.0.0.0:8888->80/tcp mystifying_golick 6d631d2ecfdd nginx \"nginx -g 'daemon of\u2026\" 2 hours ago Up 2 hours 0.0.0.0:32768->80/tcp dreamy_gates go to web browser use host_ip:9000 or loaclhost:9000 here,we have create the password you it at least 8 char long here i have to use my local environment click on as per your environment click on connect above are the portainer page is already been setup. we dont worry abot how to launch this portainer set up this alredy avaible on docker images. clik on local up here you can see how many container are present , network, volume etc Launching Application Stack with Docker Compose In this sections we are going to launch prometheus applications. the prometheus application are multiple serices present like pushgateawy and alertmanager that wy we need docker-compose file. just clone prometus repo. git clone https://github.com/vegasbrianc/prometheus.git cd prometheus cat docker-compose.yaml [output] version: '3.1' volumes: prometheus_data: {} grafana_data: {} networks: front-tier: back-tier: services: prometheus: image: prom/prometheus:v2.1.0 volumes: - ./prometheus/:/etc/prometheus/ - prometheus_data:/prometheus command: - '--config.file=/etc/prometheus/prometheus.yml' - '--storage.tsdb.path=/prometheus' - '--web.console.libraries=/usr/share/prometheus/console_libraries' - '--web.console.templates=/usr/share/prometheus/consoles' ports: - 9090:9090 links: - cadvisor:cadvisor - alertmanager:alertmanager depends_on: - cadvisor networks: - back-tier restart: always # deploy: # placement: # constraints: # - node.hostname == ${HOSTNAME} node-exporter: image: prom/node-exporter volumes: - /proc:/host/proc:ro - /sys:/host/sys:ro - /:/rootfs:ro command: - '--path.procfs=/host/proc' - '--path.sysfs=/host/sys' - --collector.filesystem.ignored-mount-points - \"^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)\" ports: - 9100:9100 networks: - back-tier restart: always deploy: mode: global alertmanager: image: prom/alertmanager ports: - 9093:9093 volumes: - ./alertmanager/:/etc/alertmanager/ networks: - back-tier restart: always command: - '--config.file=/etc/alertmanager/config.yml' - '--storage.path=/alertmanager' # deploy: # placement: # constraints: # - node.hostname == ${HOSTNAME} cadvisor: image: google/cadvisor volumes: - /:/rootfs:ro - /var/run:/var/run:rw - /sys:/sys:ro - /var/lib/docker/:/var/lib/docker:ro ports: - 8080:8080 networks: - back-tier restart: always deploy: mode: global grafana: image: grafana/grafana user: \"104\" depends_on: - prometheus ports: - 3000:3000 volumes: - grafana_data:/var/lib/grafana - ./grafana/provisioning/:/etc/grafana/provisioning/ env_file: - ./grafana/config.monitoring networks: - back-tier - front-tier restart: always In this file you can see all the services are defined with portmapping. you can run the following command to run docker compose file docker-compose up -d also use stop and down . stop for stop the all created container and down for delete all create container. docker-compose stop docker-compose down","title":"D02 docker operations"},{"location":"d02-docker-operations/#running-your-first-docker-container","text":"when your environment ready you can start your first docker container . when you running your first docker container you need docker registry. Go to docker public registry . when you visit docker hub you can see bunch of images available here. we are going to pick basic os image alpine . alpine is distribution of linux, ubuntu etc why we are choosing this image because of footprint of image and you can look at the size of the image look like 2 0r 3 mb that is really good for smoke testing and running smaller images. Now we have a basic understanding of docker command and sub commands, let us dive straight into launching our very first container docker container run alpine:3.6 uptime Where, we are using docker client to run a application/command uptime using an image by name alpine [output] Unable to find image 'alpine:3.6' locally 3.6: Pulling from library/alpine 117f30b7ae3d: Pull complete Digest: sha256:02eb5cfe4b721495135728ab4aea87418fd4edbfbf83612130a81191f0b2aae3 Status: Downloaded newer image for alpine:3.6 07:45:40 up 3:13, load average: 0.00, 0.00, 0.00 What happened? This command will Pull the alpine image file from docker hub, a cloud registry Create a runtime environment/ container with the above image Launch a program (called uptime) inside that container Stream that output to the terminal Stop the container once the program is exited Let's see what happens when we run that command again, [Output] docker run alpine uptime 07:48:06 up 3:15, load average: 0.00, 0.00, 0.00","title":"Running your first Docker Container"},{"location":"d02-docker-operations/#checking-status-of-the-containers","text":"We have understood how docker run commands works. But what if you want to see list of running containers and history of containers that had run and exited? This can be done by executing the following commands docker ps [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES This command doesn't give us any information. Because, docker ps command will only show list of container(s) which are running docker ps -l [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 988f4d90d604 alpine \"uptime\" About a minute ago Exited (0) About a minute ago fervent_hypatia The -l flag shows the last run container along with other details like image it used, command it executed, return code of that command, etc., docker ps -n 2 [output] NAMES 988f4d90d604 alpine \"uptime\" About a minute ago Exited (0) About a minute ago fervent_hypatia acea3023dca4 alpine \"uptime\" 3 minutes ago Exited (0) 3 minutes ago mad_darwin Docker gives us the flexibility to show the desirable number of last run containers. This can be achieved by using -n no_of_results flag docker ps -a [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 988f4d90d604 alpine \"uptime\" About a minute ago Exited (0) About a minute ago fervent_hypatia acea3023dca4 alpine \"uptime\" 4 minutes ago Exited (0) 4 minutes ago mad_darwin 60ffa94e69ec ubuntu:14.04.3 \"bash\" 27 hours ago Exited (0) 26 hours ago infallible_meninsky dd75c04e7d2b schoolofdevops/ghost:0.3.1 \"/entrypoint.sh npm s\" 4 days ago Exited (0) 3 days ago kickass_bardeen c082972f66d6 schoolofdevops/ghost:0.3.1 \"/entrypoint.sh npm s\" 4 days ago Exited (0) 3 days ago 0.0.0.0:80->2368/tcp sodcblog This command will show all the container we have run so far.","title":"Checking Status of the containers"},{"location":"d02-docker-operations/#making-container-persist-with-idt-options","text":"We can interact with docker containers by giving -it flags at the run time. These flags stand for i - Interactive t - tty d - detach docker container run -it alpine:3.4 sh [ouput] Unable to find image 'alpine:3.4' locally 3.4: Pulling from library/alpine e110a4a17941: Pull complete Digest: sha256:3dcdb92d7432d56604d4545cbd324b14e647b313626d99b889d0626de158f73a Status: Downloaded newer image for alpine:3.4 / # As you see, we have landed straight into sh shell of that container. This is the result of using -it flags and mentioning that container to run the sh shell. Don't try to exit that container yet. We have to execute some other commands in it to understand the next topic if you go inside the container","title":"Making container persist with -idt options"},{"location":"d02-docker-operations/#namespaced","text":"Like a full fledged OS, Docker container has its own namespaces This enables Docker container to isolate itself from the host as well as other containers Run the following commands and see that alpine container has its own namespaces and not inheriting much from host OS cat /etc/issue Welcome to Alpine Linux 3.4 Kernel \\r on an \\m (\\l) / # command pa aux [output] PID USER TIME COMMAND 1 root 0:00 sh 7 root 0:00 ps aux ifconfig [output] eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:64 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:9402 (9.1 KiB) TX bytes:0 (0.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B)","title":"Namespaced"},{"location":"d02-docker-operations/#essential-container-operations-list-logs-exec-cp-inspect-stop-rm","text":"In this section we are looking for some of the essential container operations like list,logs, exec etc. First we list the containers docker ps -a [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 60c643264937 alpine:3.4 \"sh\" 16 minutes ago Exited (0) 2 minutes ago kind_babbage 105b0de546cb ubuntu \"bash\" About an hour ago Exited (0) About an hour ago admiring_cori 8801c9dc6617 hello-world \"/hello\" 2 hours ago Exited (0) 2 hours ago hardcore_blackwell change the container name docker rename kind_babbage loop [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 60c643264937 alpine:3.4 \"sh\" 17 minutes ago Exited (0) 2 minutes ago loop 105b0de546cb ubuntu \"bash\" About an hour ago Exited (0) About an hour ago admiring_cori 8801c9dc6617 hello-world \"/hello\" 2 hours ago Exited (0) 2 hours ago hardcore_blackwell look at the name of the first container If you want to follow the log in real-time, use -f flag docker logs 5a75df45379c [output] PID USER TIME COMMAND 1 root 0:00 ps aux , uptime docker exec this command allows you to run command inside container docker exec e9f957dca1b7 ps aux [output] PID USER TIME COMMAND 1 root 0:00 /bin/sh 6 root 0:00 ps aux you can also use docker inspect command . this command gives you detail information about container docker inspect e9f957dca1b7 [output] [ { \"Id\": \"e9f957dca1b727be04357c77edbb2e2b257b22c0832d9f13b4ff06e3854a1237\", \"Created\": \"2018-09-25T08:49:47.619188383Z\", \"Path\": \"/bin/sh\", \"Args\": [], \"State\": { \"Status\": \"running\", \"Running\": true, \"Paused\": false, \"Restarting\": false, \"OOMKilled\": false, \"Dead\": false, \"Pid\": 19679, \"ExitCode\": 0, \"Error\": \"\", \"StartedAt\": \"2018-09-25T08:49:48.794801063Z\", \"FinishedAt\": \"0001-01-01T00:00:00Z\" }, \"Image\": \"sha256:174b26fe09c724368aa2c3cc8f2b979b915a33f7b50c94cd215380d56147cd60\", \"ResolvConfPath\": \"/var/lib/docker/containers/e9f957dca1b727be04357c77edbb2e2b257b22c0832d9f13b4ff06e3854a1237/resolv.conf\", \"HostnamePath\": \"/var/lib/docker/containers/e9f957dca1b727be04357c77edbb2e2b257b22c0832d9f13b4ff06e3854a1237/hostname\", \"HostsPath\": \"/var/lib/docker/containers/e9f957dca1b727be04357c77edbb2e2b257b22c0832d9f13b4ff06e3854a1237/hosts\", \"LogPath\": \"/var/lib/docker/containers/e9f957dca1b727be04357c77edbb2e2b257b22c0832d9f13b4ff06e3854a1237/e9f957dca1b727be04357c77edbb2e2b257b22c0832d9f13b4ff06e3854a1237-json.log\", \"Name\": \"/xenodochial_hugle\", \"RestartCount\": 0, \"Driver\": \"overlay2\", \"Platform\": \"linux\", \"MountLabel\": \"\", \"ProcessLabel\": \"\", \"AppArmorProfile\": \"docker-default\", \"ExecIDs\": null, \"HostConfig\": { \"Binds\": null, \"ContainerIDFile\": \"\", \"LogConfig\": { \"Type\": \"json-file\", \"Config\": {} }, \"NetworkMode\": \"default\", \"PortBindings\": {}, \"RestartPolicy\": { \"Name\": \"no\", \"MaximumRetryCount\": 0 }, \"AutoRemove\": false, \"VolumeDriver\": \"\", \"VolumesFrom\": null, \"CapAdd\": null, \"CapDrop\": null, \"Dns\": [], \"DnsOptions\": [], \"DnsSearch\": [], \"ExtraHosts\": null, \"GroupAdd\": null, \"IpcMode\": \"shareable\", \"Cgroup\": \"\", \"Links\": null, \"OomScoreAdj\": 0, \"PidMode\": \"\", \"Privileged\": false, \"PublishAllPorts\": false, \"ReadonlyRootfs\": false, \"SecurityOpt\": null, \"UTSMode\": \"\", \"UsernsMode\": \"\", \"ShmSize\": 67108864, \"Runtime\": \"runc\", \"ConsoleSize\": [ 0, 0 ], \"Isolation\": \"\", \"CpuShares\": 0, \"Memory\": 0, \"NanoCpus\": 0, \"CgroupParent\": \"\", \"BlkioWeight\": 0, \"BlkioWeightDevice\": [], \"BlkioDeviceReadBps\": null, \"BlkioDeviceWriteBps\": null, \"BlkioDeviceReadIOps\": null, \"BlkioDeviceWriteIOps\": null, \"CpuPeriod\": 0, \"CpuQuota\": 0, \"CpuRealtimePeriod\": 0, \"CpuRealtimeRuntime\": 0, \"CpusetCpus\": \"\", \"CpusetMems\": \"\", \"Devices\": [], \"DeviceCgroupRules\": null, \"DiskQuota\": 0, \"KernelMemory\": 0, \"MemoryReservation\": 0, \"MemorySwap\": 0, \"MemorySwappiness\": null, \"OomKillDisable\": false, \"PidsLimit\": 0, \"Ulimits\": null, \"CpuCount\": 0, \"CpuPercent\": 0, \"IOMaximumIOps\": 0, \"IOMaximumBandwidth\": 0 }, \"GraphDriver\": { \"Data\": { \"LowerDir\": \"/var/lib/docker/overlay2/517ee8ad38d79c97b5b4d9351058cf658265bbd752ffca764d6123cd5a45d7a3-init/diff:/var/lib/docker/overlay2/0ff2c00ee39d00f3cbdee2538e5bd08c0650b0a7531e6277513fb1411177c056/diff\", \"MergedDir\": \"/var/lib/docker/overlay2/517ee8ad38d79c97b5b4d9351058cf658265bbd752ffca764d6123cd5a45d7a3/merged\", \"UpperDir\": \"/var/lib/docker/overlay2/517ee8ad38d79c97b5b4d9351058cf658265bbd752ffca764d6123cd5a45d7a3/diff\", \"WorkDir\": \"/var/lib/docker/overlay2/517ee8ad38d79c97b5b4d9351058cf658265bbd752ffca764d6123cd5a45d7a3/work\" }, \"Name\": \"overlay2\" }, \"Mounts\": [], \"Config\": { \"Hostname\": \"e9f957dca1b7\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"Tty\": true, \"OpenStdin\": true, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ], \"Cmd\": [ \"/bin/sh\" ], \"ArgsEscaped\": true, \"Image\": \"alpine:3.4\", \"Volumes\": null, \"WorkingDir\": \"\", \"Entrypoint\": null, \"OnBuild\": null, \"Labels\": {} }, \"NetworkSettings\": { \"Bridge\": \"\", \"SandboxID\": \"a819dc4b5b24f71699cc58804ba227dfbfcd1431deab0bea5fe27ab5b97cc95e\", \"HairpinMode\": false, \"LinkLocalIPv6Address\": \"\", \"LinkLocalIPv6PrefixLen\": 0, \"Ports\": {}, \"SandboxKey\": \"/var/run/docker/netns/a819dc4b5b24\", \"SecondaryIPAddresses\": null, \"SecondaryIPv6Addresses\": null, \"EndpointID\": \"9de8e6914d71fc9b6d569a56ebaeae58aeb1fa21717aa1d94f200d22d82e0d37\", \"Gateway\": \"172.17.0.1\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"IPAddress\": \"172.17.0.2\", \"IPPrefixLen\": 16, \"IPv6Gateway\": \"\", \"MacAddress\": \"02:42:ac:11:00:02\", \"Networks\": { \"bridge\": { \"IPAMConfig\": null, \"Links\": null, \"Aliases\": null, \"NetworkID\": \"a379dcbffa8fff8004d04727d8898d46cf032a830a18d8507d7acbb3d14c552a\", \"EndpointID\": \"9de8e6914d71fc9b6d569a56ebaeae58aeb1fa21717aa1d94f200d22d82e0d37\", \"Gateway\": \"172.17.0.1\", \"IPAddress\": \"172.17.0.2\", \"IPPrefixLen\": 16, \"IPv6Gateway\": \"\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"MacAddress\": \"02:42:ac:11:00:02\", \"DriverOpts\": null } } } } ] docker copy docker cp testfile e9f957dca1b7:/opt docker diff docker diff e9f957dca1b7 [output] A /opt docker stop docker stop e9f 1b7 [output] e9f 1b7 docker remove docker rm e9f 1b7 [output] e9f 1b7","title":"Essential Container Operations - list, logs, exec, cp, inspect, stop, rm"},{"location":"d02-docker-operations/#publishing-containers-using-port-mapping","text":"Now, we have already start container, now access that application outside world, we are going through to launch container nginx web server image you can choose the image on docker hub registry for latest version. docker container run -idt -P nginx [output] Unable to find image 'nginx:latest' locally latest: Pulling from library/nginx 802b00ed6f79: Pull complete e9d0e0ea682b: Pull complete d8b7092b9221: Pull complete Digest: sha256:24a0c4b4a4c0eb97a1aabb8e29f18e917d05abfe1b7a7c07857230879ce7d3d3 Status: Downloaded newer image for nginx:latest 6d631d2ecfddb76481e2e75c6f14373dde5907e442231c38c062574cc4b880da Check the port docker ps [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6d631d2ecfdd nginx \"nginx -g 'daemon of\u2026\" 49 seconds ago Up 47 seconds 0.0.0.0:32768->80/tcp dreamy_gates the container are running on inside port 80 . If you want to acess on outside use the port 32768. docker are automatically pick up the port access this outside use your host_ip:32768 in browser. you can also define specific port use following command docker container run -idt -p 8888:80 nginx docker ps [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3104f3f3c062 nginx \"nginx -g 'daemon of\u2026\" 52 seconds ago Up 50 seconds 0.0.0.0:8888->80/tcp mystifying_golick 6d631d2ecfdd nginx \"nginx -g 'daemon of\u2026\" 11 minutes ago Up 11 minutes 0.0.0.0:32768->80/tcp dreamy_gates we going to deploy another web based application ghost docker run -d --name ghost -p 3001:2368 ghost:alpine [output] Unable to find image 'ghost:alpine' locally alpine: Pulling from library/ghost 4fe2ade4980c: Already exists eeb7d76f44e7: Pull complete e35f88fcc259: Pull complete b4d59ef07366: Pull complete dcee404d51ae: Pull complete f0d2c5f09664: Pull complete 6feecb37b3bd: Pull complete 4e29bf9bf09f: Pull complete Digest: sha256:d1d329a9e28096003ddbce69f3fc4a81b72c2c0c9e88426fc432fd3f0e1146e1 Status: Downloaded newer image for ghost:alpine 4c84890e1f4438a647b287751beeda02490ed7a312c05ae4a64ba7f01047a76b docker ps [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4c84890e1f44 ghost:alpine \"docker-entrypoint.s\u2026\" 40 seconds ago Up 38 seconds 0.0.0.0:3001->2368/tcp ghost 3104f3f3c062 nginx \"nginx -g 'daemon of\u2026\" 8 minutes ago Up 8 minutes 0.0.0.0:8888->80/tcp mystifying_golick 6d631d2ecfdd nginx \"nginx -g 'daemon of\u2026\" 19 minutes ago Up 19 minutes 0.0.0.0:32768->80/tcp dreamy_gates this application are running on port 3001 you can see on web browser host_ip:3001 or localhost:3001","title":"Publishing containers using port mapping"},{"location":"d02-docker-operations/#using-docker-instead-of-vms-to-create-development-environments","text":"If you have using vm to runing docker container it takes some extra time to run docker container . if you want to see all the images use following command. this shows you all the present images in your local environment. docker images [output] ghost alpine fd8dde6880e2 4 days ago 422MB alpine 3.4 174b26fe09c7 13 days ago 4.82MB alpine latest 196d12cf6ab1 13 days ago 4.41MB hello-world latest 4ab4c602aa5e 2 weeks ago 1.84kB ubuntu latest cd6d8154f1e1 2 weeks ago 84.1MB if wanna see all the layers of docker image use following command docker image history ghost:alpine [output] IMAGE CREATED CREATED BY SIZE COMMENT fd8dde6880e2 4 days ago /bin/sh -c #(nop) CMD [\"node\" \"current/inde\u2026 0B <missing> 4 days ago /bin/sh -c #(nop) EXPOSE 2368/tcp 0B <missing> 4 days ago /bin/sh -c #(nop) ENTRYPOINT [\"docker-entry\u2026 0B <missing> 4 days ago /bin/sh -c #(nop) COPY file:984b6359fb5468bd\u2026 584B <missing> 4 days ago /bin/sh -c #(nop) VOLUME [/var/lib/ghost/co\u2026 0B <missing> 4 days ago /bin/sh -c #(nop) WORKDIR /var/lib/ghost 0B <missing> 4 days ago /bin/sh -c set -ex; mkdir -p \"$GHOST_INSTAL\u2026 301MB <missing> 4 days ago /bin/sh -c #(nop) ENV GHOST_VERSION=2.1.3 0B <missing> 10 days ago /bin/sh -c #(nop) ENV GHOST_CONTENT=/var/li\u2026 0B <missing> 10 days ago /bin/sh -c #(nop) ENV GHOST_INSTALL=/var/li\u2026 0B <missing> 10 days ago /bin/sh -c npm install -g \"ghost-cli@$GHOST_\u2026 51.3MB <missing> 10 days ago /bin/sh -c #(nop) ENV GHOST_CLI_VERSION=1.9\u2026 0B <missing> 13 days ago /bin/sh -c #(nop) ENV NODE_ENV=production 0B <missing> 13 days ago /bin/sh -c apk add --no-cache bash 3.82MB <missing> 13 days ago /bin/sh -c apk add --no-cache 'su-exec>=0.2' 31.8kB <missing> 13 days ago /bin/sh -c #(nop) CMD [\"node\"] 0B <missing> 13 days ago /bin/sh -c apk add --no-cache --virtual .bui\u2026 4.53MB <missing> 13 days ago /bin/sh -c #(nop) ENV YARN_VERSION=1.9.4 0B <missing> 13 days ago /bin/sh -c addgroup -g 1000 node && addu\u2026 56.7MB <missing> 13 days ago /bin/sh -c #(nop) ENV NODE_VERSION=8.12.0 0B <missing> 13 days ago /bin/sh -c #(nop) CMD [\"/bin/sh\"] 0B <missing> 13 days ago /bin/sh -c #(nop) ADD file:25c10b1d1b41d46a1\u2026 4.41MB If you want to use docker devlopment envireonment just pull the ubuntu and centos image you can pull images using docker images docker pull ubuntu [output] Using default tag: latest latest: Pulling from library/ubuntu Digest: sha256:de774a3145f7ca4f0bd144c7d4ffb2931e06634f11529653b23eba85aef8e378 Status: Image is up to date for ubuntu:latest pulling centos docker pull centos [output] Using default tag: latest latest: Pulling from library/centos 256b176beaff: Pull complete Digest: sha256:6f6d986d425aeabdc3a02cb61c02abb2e78e57357e92417d6d58332856024faf Status: Downloaded newer image for centos:latest here, the images are ready we are going to create dev environment using ubuntu image docker container run -idt --name dev --net host ubuntu bash 158dfe96692f9381842d009abfea428614fed4d9a16de68d18b408549315fbd9 docker container run -idt --name dev-centos --net host centos bash 99be0c7548ab3c762d7af2fa0cc73a5ad1505589424d82bea2c065a4f1d3bdf7 docker ps -n 2 [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 99be0c7548ab centos \"bash\" 57 seconds ago Up 56 seconds dev-centos 158dfe96692f ubuntu \"bash\" 2 minutes ago Up 2 minutes dev if you want to go inside container use following command docker exec -it dev bash you can check procees inside the container ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 18508 3004 pts/0 Ss+ 10:15 0:00 bash root 10 0.0 0.0 18508 3384 pts/1 Ss 10:20 0:00 bash root 20 0.0 0.0 34400 2772 pts/1 R+ 10:21 0:00 ps aux you can also run following command apt-get update apt-get install vim touch /opt/testfile docker stop dev docker start dev you can persist the data across. make the changes of dev environment as well , we wiiljust stop and start contaoner see the changes before start and stop. docker exec -it dev bash excute the following caommand which vim ls /opt/","title":"Using docker instead of VMs to create development environments"},{"location":"d02-docker-operations/#portainer-web-console-to-managing-docker-environemnts","text":"In this Section we are goiing for portainer web console which will allow you web based application which manages your local or remote docker environment. you can also visit the portainer docker volume create portainer_data [output] portainer_data After creating volume excute following command docker run -d -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer [output] Unable to find image 'portainer/portainer:latest' locally latest: Pulling from portainer/portainer d1e017099d17: Pull complete d4e5419541f5: Pull complete Digest: sha256:07c0e19e28e18414dd02c313c36b293758acf197d5af45077e3dd69c630e25cc Status: Downloaded newer image for portainer/portainer:latest db7a8c18cdfcae46d6ccb9d3d5ad0a48568fdc8e5827f478f0c44b95b8235bdf which will aloow container to connect to docker daemon and mange its on. docker ps [output] CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES db7a8c18cdfc portainer/portainer \"/portainer\" About a minute ago Up About a minute 0.0.0.0:9000->9000/tcp zen_jepsen 99be0c7548ab centos \"bash\" 32 minutes ago Up 32 minutes dev-centos 158dfe96692f ubuntu \"bash\" 34 minutes ago Up 34 minutes dev 4c84890e1f44 ghost:alpine \"docker-entrypoint.s\u2026\" About an hour ago Up About an hour 0.0.0.0:3001->2368/tcp ghost 3104f3f3c062 nginx \"nginx -g 'daemon of\u2026\" About an hour ago Up About an hour 0.0.0.0:8888->80/tcp mystifying_golick 6d631d2ecfdd nginx \"nginx -g 'daemon of\u2026\" 2 hours ago Up 2 hours 0.0.0.0:32768->80/tcp dreamy_gates go to web browser use host_ip:9000 or loaclhost:9000 here,we have create the password you it at least 8 char long here i have to use my local environment click on as per your environment click on connect above are the portainer page is already been setup. we dont worry abot how to launch this portainer set up this alredy avaible on docker images. clik on local up here you can see how many container are present , network, volume etc","title":"Portainer - Web console to managing Docker Environemnts"},{"location":"d02-docker-operations/#launching-application-stack-with-docker-compose","text":"In this sections we are going to launch prometheus applications. the prometheus application are multiple serices present like pushgateawy and alertmanager that wy we need docker-compose file. just clone prometus repo. git clone https://github.com/vegasbrianc/prometheus.git cd prometheus cat docker-compose.yaml [output] version: '3.1' volumes: prometheus_data: {} grafana_data: {} networks: front-tier: back-tier: services: prometheus: image: prom/prometheus:v2.1.0 volumes: - ./prometheus/:/etc/prometheus/ - prometheus_data:/prometheus command: - '--config.file=/etc/prometheus/prometheus.yml' - '--storage.tsdb.path=/prometheus' - '--web.console.libraries=/usr/share/prometheus/console_libraries' - '--web.console.templates=/usr/share/prometheus/consoles' ports: - 9090:9090 links: - cadvisor:cadvisor - alertmanager:alertmanager depends_on: - cadvisor networks: - back-tier restart: always # deploy: # placement: # constraints: # - node.hostname == ${HOSTNAME} node-exporter: image: prom/node-exporter volumes: - /proc:/host/proc:ro - /sys:/host/sys:ro - /:/rootfs:ro command: - '--path.procfs=/host/proc' - '--path.sysfs=/host/sys' - --collector.filesystem.ignored-mount-points - \"^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)\" ports: - 9100:9100 networks: - back-tier restart: always deploy: mode: global alertmanager: image: prom/alertmanager ports: - 9093:9093 volumes: - ./alertmanager/:/etc/alertmanager/ networks: - back-tier restart: always command: - '--config.file=/etc/alertmanager/config.yml' - '--storage.path=/alertmanager' # deploy: # placement: # constraints: # - node.hostname == ${HOSTNAME} cadvisor: image: google/cadvisor volumes: - /:/rootfs:ro - /var/run:/var/run:rw - /sys:/sys:ro - /var/lib/docker/:/var/lib/docker:ro ports: - 8080:8080 networks: - back-tier restart: always deploy: mode: global grafana: image: grafana/grafana user: \"104\" depends_on: - prometheus ports: - 3000:3000 volumes: - grafana_data:/var/lib/grafana - ./grafana/provisioning/:/etc/grafana/provisioning/ env_file: - ./grafana/config.monitoring networks: - back-tier - front-tier restart: always In this file you can see all the services are defined with portmapping. you can run the following command to run docker compose file docker-compose up -d also use stop and down . stop for stop the all created container and down for delete all create container. docker-compose stop docker-compose down","title":"Launching Application Stack with Docker Compose"},{"location":"d03-docker-images/","text":"Building Docker Images In this lab, you are going to learn how to bulild images, publish those and work with the docker registry. Building an image manually with docker commit Lets take the following application as an example. You first need to start by cloning the code, git clone https://github.com/schoolofdevops/facebooc.git after cloning this repo we are going to launch ubuntu image this application running on port 1600 that why we are already exposing port. docker container run -idt --name fb -p 16000:16000 ubuntu bash connect to that container using following command docker exec -it fb bash after connecting that container use following instructions. Install following package: build-essential make libsqlite3-dev sqlite3 sudo apt-get update sudo apt-get install -yq build-essential make libsqlite3-dev sqlite3 after installing this packages we need source code cpoy your source code in insisde the container. docker cp facebooc/ fb:/opt/ after copying the data go inside the container docker exec -it fb bash switch the dir. cd /opt/facebooc/ then Build the application using following command make all Run the application using binary bin/facebooc now go to the web browser host_ip:16000 or localhost:16000 then exit the container commit container using following command including your own tag with your docker hub id docker container commit fb initcron/fb:v1 After creating image push to docker hub registry docker login docker image push initcron/fb:v1 Automatiing image builds with a Dockerfile Above section we build the image using manual approch. In this we going to dockerfile to build image automation. just clone the repo. using following command. git clone https://github.com/schoolofdevops/facebooc.git cd facebooc git checkout docker you can see the Dockerfile cat Dockerfile [output] FROM ubuntu WORKDIR /opt/facebooc RUN apt-get update && \\ apt-get install -yq build-essential make git libsqlite3-dev sqlite3 COPY . /opt/facebooc RUN make all EXPOSE 16000 CMD \"bin/facebooc\" then build docker image image docker image build -t initcron/fb:v2 . after build image launch it docker container run -idt -P initcron/fb:v2","title":"Building Docker Images"},{"location":"d03-docker-images/#building-docker-images","text":"In this lab, you are going to learn how to bulild images, publish those and work with the docker registry.","title":"Building Docker Images"},{"location":"d03-docker-images/#building-an-image-manually-with-docker-commit","text":"Lets take the following application as an example. You first need to start by cloning the code, git clone https://github.com/schoolofdevops/facebooc.git after cloning this repo we are going to launch ubuntu image this application running on port 1600 that why we are already exposing port. docker container run -idt --name fb -p 16000:16000 ubuntu bash connect to that container using following command docker exec -it fb bash after connecting that container use following instructions. Install following package: build-essential make libsqlite3-dev sqlite3 sudo apt-get update sudo apt-get install -yq build-essential make libsqlite3-dev sqlite3 after installing this packages we need source code cpoy your source code in insisde the container. docker cp facebooc/ fb:/opt/ after copying the data go inside the container docker exec -it fb bash switch the dir. cd /opt/facebooc/ then Build the application using following command make all Run the application using binary bin/facebooc now go to the web browser host_ip:16000 or localhost:16000 then exit the container commit container using following command including your own tag with your docker hub id docker container commit fb initcron/fb:v1 After creating image push to docker hub registry docker login docker image push initcron/fb:v1","title":"Building an image manually with docker commit"},{"location":"d03-docker-images/#automatiing-image-builds-with-a-dockerfile","text":"Above section we build the image using manual approch. In this we going to dockerfile to build image automation. just clone the repo. using following command. git clone https://github.com/schoolofdevops/facebooc.git cd facebooc git checkout docker you can see the Dockerfile cat Dockerfile [output] FROM ubuntu WORKDIR /opt/facebooc RUN apt-get update && \\ apt-get install -yq build-essential make git libsqlite3-dev sqlite3 COPY . /opt/facebooc RUN make all EXPOSE 16000 CMD \"bin/facebooc\" then build docker image image docker image build -t initcron/fb:v2 . after build image launch it docker container run -idt -P initcron/fb:v2","title":"Automatiing image builds with a Dockerfile"},{"location":"docker_index/","text":"Just enough Docker Chapter 1: Setting up Docker Chapter 2: Launching and Operating Containers Chapter 3: Building and Publishing Images","title":"Docker"},{"location":"docker_index/#just-enough-docker","text":"Chapter 1: Setting up Docker Chapter 2: Launching and Operating Containers Chapter 3: Building and Publishing Images","title":"Just enough Docker"},{"location":"host_pattern/","text":"Inventories and host patterns In this section we are going to Deploy applications frontend , carts and catalogue. The part of the code is alredy avaible that repo. we have alredy cloned. we just provide some commom configuration. Following is our recommended layout for organizing your ansible code. There are a couple of alternatives as discusses on official documentation ansible |\\ | |_ environments | \\ | |_ dev | | | |_ prod | | |\\ | |_ group_vars | \\ | |_ all | | | |_ dev | | | |_ prod | |\\ | |_ roles | \\ | |_ app1 | | | |_ app2 | | |\\ | | | \\ | |_ playbook1.yml | | | | | |_ playbook2.yml | | | |_ _ ansible.cfg This is the place where you would add your inventories ansible \\ environments \\ |_ dev | |_ prod then try to ping using following command ansible all -m ping [output] lb | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } frontend | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } carts | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } catalogue | SUCCESS => { \"changed\": false, patterns ansible 'frontend' -m ping ansible 'dev' -m ping ansible 'dev:!frontend' -m ping ansible 'carts:frontend' -m ping","title":"Host pattern"},{"location":"host_pattern/#inventories-and-host-patterns","text":"In this section we are going to Deploy applications frontend , carts and catalogue. The part of the code is alredy avaible that repo. we have alredy cloned. we just provide some commom configuration. Following is our recommended layout for organizing your ansible code. There are a couple of alternatives as discusses on official documentation ansible |\\ | |_ environments | \\ | |_ dev | | | |_ prod | | |\\ | |_ group_vars | \\ | |_ all | | | |_ dev | | | |_ prod | |\\ | |_ roles | \\ | |_ app1 | | | |_ app2 | | |\\ | | | \\ | |_ playbook1.yml | | | | | |_ playbook2.yml | | | |_ _ ansible.cfg This is the place where you would add your inventories ansible \\ environments \\ |_ dev | |_ prod then try to ping using following command ansible all -m ping [output] lb | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } frontend | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } carts | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } catalogue | SUCCESS => { \"changed\": false, patterns ansible 'frontend' -m ping ansible 'dev' -m ping ansible 'dev:!frontend' -m ping ansible 'carts:frontend' -m ping","title":"Inventories and host patterns"},{"location":"outline/","text":"Outline This is an example of \"frontmatter\", which comes before the main text of the book. Course Outline Module 1 : Introduction and Use Case Section 1: Codifying Devops Why Devops History Principles and Practices Section 2: Use Case Workshop Description of Use Case Organization Goals Pain Points Diagnosing the issues Solution Design Module 2 : Revision Control Section 1: Git quick dive Git and Distributed Revision Control Repos Branching and Merging Github Branching Strategy Git References Lab Setting up repos Create a devops repo Module 03: Containers Advantages of using containers Portability Consistency Density Eco System Speed Docker quick dive Running Containers Operating Containers Port Mapping Building Docker Images Module 04: Infrastructure as a Code Section 1: Ansible Overview Why Ansible IaaC Convergence Idempotence Ansible Concepts Inventory Playbooks Roles Modules Vars/Templates Section 2: Creating Ansible code for Demo App Playbooks for System Configurations Application Configurations Deployment Additional Code for Provisioning Automation Module 05: Continuous Integration Section 01: Setting up a CI Pipeline with Jenkins Setup Jenkins Commit Stage Jobs build/compile unit test static code analysis Artifacts Management Functional Acceptance Testing Deploy to Staging NFR Testing Module 6: CI with Docker Section 1 : Dockerizing App Stack * Build Dockerfiles * Create Docker Compose specs Module 7: Cloud Computing Section 01: Overview of AWS Cloud Computing AWS Services VPC EC2 RDS S3 Cloud Design considerations Availability Scalability Manageability Security Module 8 : Continuous Delivery and Deployment Chapter 13: Kubernetes: Taking Containers to Production * COEs and intro to k8s * k8s Quick Dive * Pods * deployments * services * Ingress * rollouts Chapter 14: Deploying Demo app in Production Deploy k8s Cluster /Minikube Create k8s objects deployment service ingress Release Management Zero Downtime Blue Green Canary Module 9 : Cloud Provisioning Section 1 : Terraform * Module 10: Monitoring Why Monitoring ? What to monitor Logs APM Health Labs: Setup log monitoring Setup performance monitoring Health Monitoring and Alerting","title":"Outline"},{"location":"outline/#outline","text":"This is an example of \"frontmatter\", which comes before the main text of the book.","title":"Outline"},{"location":"outline/#course-outline","text":"Module 1 : Introduction and Use Case Section 1: Codifying Devops Why Devops History Principles and Practices Section 2: Use Case Workshop Description of Use Case Organization Goals Pain Points Diagnosing the issues Solution Design Module 2 : Revision Control Section 1: Git quick dive Git and Distributed Revision Control Repos Branching and Merging Github Branching Strategy Git References Lab Setting up repos Create a devops repo Module 03: Containers Advantages of using containers Portability Consistency Density Eco System Speed Docker quick dive Running Containers Operating Containers Port Mapping Building Docker Images Module 04: Infrastructure as a Code Section 1: Ansible Overview Why Ansible IaaC Convergence Idempotence Ansible Concepts Inventory Playbooks Roles Modules Vars/Templates Section 2: Creating Ansible code for Demo App Playbooks for System Configurations Application Configurations Deployment Additional Code for Provisioning Automation Module 05: Continuous Integration Section 01: Setting up a CI Pipeline with Jenkins Setup Jenkins Commit Stage Jobs build/compile unit test static code analysis Artifacts Management Functional Acceptance Testing Deploy to Staging NFR Testing Module 6: CI with Docker Section 1 : Dockerizing App Stack * Build Dockerfiles * Create Docker Compose specs Module 7: Cloud Computing Section 01: Overview of AWS Cloud Computing AWS Services VPC EC2 RDS S3 Cloud Design considerations Availability Scalability Manageability Security Module 8 : Continuous Delivery and Deployment Chapter 13: Kubernetes: Taking Containers to Production * COEs and intro to k8s * k8s Quick Dive * Pods * deployments * services * Ingress * rollouts Chapter 14: Deploying Demo app in Production Deploy k8s Cluster /Minikube Create k8s objects deployment service ingress Release Management Zero Downtime Blue Green Canary Module 9 : Cloud Provisioning Section 1 : Terraform * Module 10: Monitoring Why Monitoring ? What to monitor Logs APM Health Labs: Setup log monitoring Setup performance monitoring Health Monitoring and Alerting","title":"Course Outline"},{"location":"preface/","text":"Preface This is an example of \"frontmatter\", which comes before the main text of the book. Course Outline Chapter 01: Codifying Devops Why Devops History Principles and Practices Chapter 02: Use Case Workshop Description of Use Case Organization Goals Pain Points Diagnosing the issues Solution Design Chapter 03: Git quick dive Git and Distributed Revision Control Repos Branching and Merging Github Branching Strategy Git References Lab Setting up repos Create a devops repo Chapter 04: Ansible quick dive Why Ansible IaaC Convergence Idempotence Ansible Concepts Inventory Playbooks Roles Modules Vars/Templates Chapter 05: Creating Ansible code for Demo App Playbooks for System Configurations Application Configurations Deployment Additional Code for Provisioning Automation Chapter 06: Provisioning Automation Vagrant Labs: Create dev env Integrate with Ansible Chapter 07: Continous Integration Theory Chapter 08: Setting up a CI Pipeline with Jenkins Setup Jenkins Commit Stage Jobs build/compile unit test static code analysis Artifacts Management Functional Acceptance Testing Deploy to Staging NFR Testing Chapter 09: Cloud and AWS* Cloud and Devop AWS Chapter 10: Deploy a prod Environment on AWS Design considerations Availability Scalability Manageability Security Deploy to prod, integrate with Jenkins Chapter 11: Containers and Docker Advantages of using containers Portability Consistency Density Eco System Speed Docker quick dive Running Containers Operating Containers Port Mapping Building Docker Images Chapter 12: Dockerizing App Stack Build Dockerfiles Create Docker Compose specs Chapter 13: Kubernetes: Taking Containers to Production COEs and intro to k8s k8s Quick Dive Pods deployments services Ingress rollouts Chapter 14: Deploying Demo app in Production Deploy k8s Cluster /Minikube Create k8s objects deployment service ingress Release Management Zero Downtime Blue Green Canary Chapter 15: Monitoring Why Monitoring ? What to monitor Logs APM Health Labs: Setup log monitoring Setup performance monitoring Health Monitoring and Alerting","title":"Outline"},{"location":"preface/#preface","text":"This is an example of \"frontmatter\", which comes before the main text of the book.","title":"Preface"},{"location":"preface/#course-outline","text":"Chapter 01: Codifying Devops Why Devops History Principles and Practices Chapter 02: Use Case Workshop Description of Use Case Organization Goals Pain Points Diagnosing the issues Solution Design Chapter 03: Git quick dive Git and Distributed Revision Control Repos Branching and Merging Github Branching Strategy Git References Lab Setting up repos Create a devops repo Chapter 04: Ansible quick dive Why Ansible IaaC Convergence Idempotence Ansible Concepts Inventory Playbooks Roles Modules Vars/Templates Chapter 05: Creating Ansible code for Demo App Playbooks for System Configurations Application Configurations Deployment Additional Code for Provisioning Automation Chapter 06: Provisioning Automation Vagrant Labs: Create dev env Integrate with Ansible Chapter 07: Continous Integration Theory Chapter 08: Setting up a CI Pipeline with Jenkins Setup Jenkins Commit Stage Jobs build/compile unit test static code analysis Artifacts Management Functional Acceptance Testing Deploy to Staging NFR Testing Chapter 09: Cloud and AWS* Cloud and Devop AWS Chapter 10: Deploy a prod Environment on AWS Design considerations Availability Scalability Manageability Security Deploy to prod, integrate with Jenkins Chapter 11: Containers and Docker Advantages of using containers Portability Consistency Density Eco System Speed Docker quick dive Running Containers Operating Containers Port Mapping Building Docker Images Chapter 12: Dockerizing App Stack Build Dockerfiles Create Docker Compose specs Chapter 13: Kubernetes: Taking Containers to Production COEs and intro to k8s k8s Quick Dive Pods deployments services Ingress rollouts Chapter 14: Deploying Demo app in Production Deploy k8s Cluster /Minikube Create k8s objects deployment service ingress Release Management Zero Downtime Blue Green Canary Chapter 15: Monitoring Why Monitoring ? What to monitor Logs APM Health Labs: Setup log monitoring Setup performance monitoring Health Monitoring and Alerting","title":"Course Outline"},{"location":"roles/","text":"Roles for modular configurations Now is the time to start creating modular, reusable library of code for application configurations. In this chapter, we are going to write such modular code, in the form of roles and setup application server. We are going to create the roles with following specs, frontend catalogue cart Create roles directory mkdir roles Generate role scaffolding using ansible-galaxy ansible-galaxy init --offline --init-path=roles frontend Validate tree roles/ [output] roles/ \u2514\u2500\u2500 apache \u251c\u2500\u2500 defaults \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 files \u251c\u2500\u2500 handlers \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 meta \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 templates \u251c\u2500\u2500 tests \u2502 \u251c\u2500\u2500 inventory \u2502 \u2514\u2500\u2500 test.yml \u2514\u2500\u2500 vars \u2514\u2500\u2500 main.yml Playbooks to map hosts to roles Create a playbook for app servers frontend.yaml , with following contents --- - hosts: frontend become: true roles: - frontend ansible-playbook frontend.yml","title":"Roles"},{"location":"roles/#roles-for-modular-configurations","text":"Now is the time to start creating modular, reusable library of code for application configurations. In this chapter, we are going to write such modular code, in the form of roles and setup application server. We are going to create the roles with following specs, frontend catalogue cart Create roles directory mkdir roles Generate role scaffolding using ansible-galaxy ansible-galaxy init --offline --init-path=roles frontend Validate tree roles/ [output] roles/ \u2514\u2500\u2500 apache \u251c\u2500\u2500 defaults \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 files \u251c\u2500\u2500 handlers \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 meta \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 templates \u251c\u2500\u2500 tests \u2502 \u251c\u2500\u2500 inventory \u2502 \u2514\u2500\u2500 test.yml \u2514\u2500\u2500 vars \u2514\u2500\u2500 main.yml","title":"Roles for modular configurations"},{"location":"roles/#playbooks-to-map-hosts-to-roles","text":"Create a playbook for app servers frontend.yaml , with following contents --- - hosts: frontend become: true roles: - frontend ansible-playbook frontend.yml","title":"Playbooks to map hosts to roles"},{"location":"setting_codespace/","text":"Setting up codespaces environment In this section we are going to see how to set codespaces environment using docker and docker compose. * Clone the git repo. https://github.com/udbc/bootcamp.git Start Codespaces IDE After installing Docker-Engine and Docker-Compose, change directory into the corresponding tool you want to learn. For example, let us assume that you want to learn puppet. In that case, cd bootcamp/setup/ Then all you need to do is to run docker-compose up -d This single command will initialize your Codespaces IDE. Use Codespaces IDE To use Codespaces IDE, Open your browser. Visit your machine's IP with port 8000. (Ex. http://192.168.0.60:8080) You will be asked for your e-mail address. Enter it and you are good to go. Now you will be presented with the Codespaces IDE console. After setting that environment try to connect other node using ssh and password codespaces from this ansible controller ssh devops@frontend ssh devops@carts After that fork the source git repo. https://github.com/udbc/bootcamp.git Then, click on Repository tab and clone it","title":"Setting codespace"},{"location":"setting_codespace/#setting-up-codespaces-environment","text":"In this section we are going to see how to set codespaces environment using docker and docker compose. * Clone the git repo. https://github.com/udbc/bootcamp.git","title":"Setting up codespaces environment"},{"location":"setting_codespace/#start-codespaces-ide","text":"After installing Docker-Engine and Docker-Compose, change directory into the corresponding tool you want to learn. For example, let us assume that you want to learn puppet. In that case, cd bootcamp/setup/ Then all you need to do is to run docker-compose up -d This single command will initialize your Codespaces IDE.","title":"Start Codespaces IDE"},{"location":"setting_codespace/#use-codespaces-ide","text":"To use Codespaces IDE, Open your browser. Visit your machine's IP with port 8000. (Ex. http://192.168.0.60:8080) You will be asked for your e-mail address. Enter it and you are good to go. Now you will be presented with the Codespaces IDE console. After setting that environment try to connect other node using ssh and password codespaces from this ansible controller ssh devops@frontend ssh devops@carts After that fork the source git repo. https://github.com/udbc/bootcamp.git Then, click on Repository tab and clone it","title":"Use Codespaces IDE"},{"location":"yet_another_chapter/","text":"Yet another chapter This chapter left intentionally blank","title":"Yet *another* chapter"},{"location":"yet_another_chapter/#yet-another-chapter","text":"This chapter left intentionally blank","title":"Yet another chapter"}]}